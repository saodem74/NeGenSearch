Multi-task learning From Wikipedia, the free encyclopedia Jump to navigation Jump to search Solving multiple machine learning tasks at the same time Multi-task learning MTL is a subfield of machine learning in which multiple learning tasks are solved at the same time, while exploiting commonalities and differences across tasks. This can result in improved learning efficiency and prediction accuracy for the task-specific models, when compared to training the models separately. 1  2  3  Early versions of MTL were called hints 4  5  . In a widely cited 1997 paper, Rich Caruana gave the following characterization Multitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias . It does this by learning tasks in parallel while using a shared representation  what is learned for each task can help other tasks be learned better. 3  In the classification context, MTL aims to improve the performance of multiple classification tasks by learning them jointly. One example is a spam-filter, which can be treated as distinct but related classification tasks across different users. To make this more concrete, consider that different people have different distributions of features which distinguish spam emails from legitimate ones, for example an English speaker may find that all emails in Russian are spam, not so for Russian speakers. Yet there is a definite commonality in this classification task across users, for example one common feature might be text related to money transfer. Solving each users spam classification problem jointly via MTL can let the solutions inform each other an d improve performance. 6  Further examples of settings for MTL include multiclass classification and multi-label classification . 7  Multi-task learning works because regularization induced by requiring an algorithm to perform well on a related task can be superior to regularization that prevents overfitting by penalizing all complexity uniformly. One situation where MTL may be particularly helpful is if the tasks share significant commonalities and are generally slightly under sampled. 8  6  However, as discussed below, MTL has also been shown to be beneficial for learning unrelated tasks. 8  9  Contents 1 Methods 1.1 Task grouping and overlap 1.2 Exploiting unrelated tasks 1.3 Transfer of knowledge 1.4 Group online adaptive learning 2 Mathematics 2.1 Reproducing Hilbert space of vector valued functions RKHSvv 2.1.1 RKHSvv concepts 2.1.2 Separable kernels 2.1.3 Known task structure 2.1.3.1 Task structure representations 2.1.3.2 Task structure examples 2.1.4 Learning tasks together with their structure 2.1.4.1 Optimization of Q 2.1.4.2 Special cases 2.1.4.3 Generalizations 3 Applications 3.1 Spam filtering 3.2 Web search 3.3 RoboEarth 4 Software package 5 See also 6 References 7 External links 7.1 Software Methods  edit  Task grouping and overlap  edit  Within the MTL paradigm, information can be shared across some or all of the tasks. Depending on the structure of task relatedness, one may want to share information selectively across the tasks. For example, tasks may be grouped or exist in a hierarchy, or be related according to some general metric. Suppose, as developed more formally below, that the parameter vector modeling each task is a linear combination of some underlying basis. Similarity in terms of this basis can indicate the relatedness of the tasks. For example, with sparsity , overlap of nonzero coefficients across tasks indicates commonality. A task grouping then corresponds to those tasks lying in a subspace generated by some subset of basis elements, where tasks in different groups may be disjoint or overlap arbitrarily in terms of their bases. 10  Task relatedness can be imposed a priori or learned from the data. 7  11  Hierarchical task relatedness can also be exploited implicitly without assuming a priori knowledge or learning relations explicitly. 8  12  . For example, the explicit learning of sample relevance across tasks can be done to guarantee the effectiveness of joint learning across multiple domains. 8  Exploiting unrelated tasks  edit  One can attempt learning a group of principal tasks using a group of auxiliary tasks, unrelated to the principal ones. In many applications, joint learning of unrelated tasks which use the same input data can be beneficial. The reason is that prior knowledge about task relatedness can lead to sparser and more informative representations for each task grouping, essentially by sc reening out idiosyncrasies of the data distribution. Novel methods which builds on a prior multitask methodology by favoring a shared low-dimensional representation within each task grouping have been proposed. The programmer can impose a penalty on tasks from different groups which encourages the two representations to be orthogonal . Experiments on synthetic and real data have indicated that incorporating unrelated tasks can result in significant improvements over standard multi-task learning methods. 9  Transfer of knowledge  edit  Related to multi-task learning is the concept of knowledge transfer. Whereas traditional multi-task learning implies that a shared representation is developed concurrently across tasks, transfer of knowledge implies a sequentially shared representation. Large scale machine learning projects such as the deep convolutional neural network GoogLeNet , 13  an image-based object classifier, can develop robust representations which may be useful to further algorithms learning related tasks. For example, the pre-trained model can be used as a feature extractor to perform pre-processing for another learning algorithm. Or the pre-trained model can be used to initialize a model with similar architecture which is then fine-tuned to lea rn a different classification task. 14  Group online adaptive learning  edit  Traditionally Multi-task learning and transfer of knowledge are applied to stationary learning settings. Their extension to non-stationary environments is termed Group online adaptive learning GOAL. 15  Sharing information could be particularly useful if learners operate in continuously changing environments, because a learner could benefit from previous experience of another learner to quickly adapt to their new environment. Such group-adaptive learning has numerous applications, from predicting financial time-series, through content recommendation systems, to visual underst anding for adaptive autonomous agents. Mathematics  edit  Reproducing Hilbert space of vector valued functions RKHSvv  edit  The MTL problem can be cast within the context of RKHSvv a complete inner product space of vector-valued functions equipped with a reproducing kernel . In particular, recent focus has been on cases where task structure can be identified via a separable kernel, described below. The presentation here derives from Ciliberto et al., 2015. 7  RKHSvv concepts  edit  Suppose the training data set is S t    x i t , y i t   i  1 n t displaystyle mathcal S_tx_it,y_it_i1n_t , with x i t  X displaystyle x_itin mathcal X , y i t  Y displaystyle y_itin mathcal Y , where t indexes task, and t  1 , . . . , T displaystyle tin 1,...,T . Let n   t  1 T n t displaystyle nsum _t1Tn_t . In this setting there is a consistent input and output space and the same loss function L  R  R  R  displaystyle mathcal Lmathbb R times mathbb R rightarrow mathbb R _ for each task . This results in the regularized machine learning problem min f  H  t  1 T 1 n t  i  1 n t L  y i t , f t  x i t       f   H 2 displaystyle min _fin mathcal Hsum _t1Tfrac 1n_tsum _i1n_tmathcal Ly_it,f_tx_itlambda f_mathcal H2          1  where H displaystyle mathcal H is a vector valued reproducing kernel Hilbert space with functions f  X  Y T displaystyle fmathcal Xrightarrow mathcal YT having components f t  X  Y displaystyle f_tmathcal Xrightarrow mathcal Y . The reproducing kernel for the space H displaystyle mathcal H of functions f  X  R T displaystyle fmathcal Xrightarrow mathbb R T is a symmetric matrix-valued function   X  X  R T  T displaystyle Gamma mathcal Xtimes mathcal Xrightarrow mathbb R Ttimes T , such that    , x  c  H displaystyle Gamma cdot ,xcin mathcal H and the following reproducing property holds  f  x  , c  R T   f ,   x ,   c  H displaystyle langle fx,crangle _mathbb R Tlangle f,Gamma x,cdot crangle _mathcal H          2  The reproducing kernel gives rise to a representer theorem showing that any solution to equation 1 has the form f  x    t  1 T  i  1 n t   x , x i t  c i t displaystyle fxsum _t1Tsum _i1n_tGamma x,x_itc_it          3  Separable kernels  edit  The form of the kernel  induces both the representation of the feature space and structures the output across tasks. A natural simplification is to choose a separable kernel, which factors into separate kernels on the input space X and on the tasks  1 , . . . , T  displaystyle 1,...,T . In this case the kernel relating scalar components f t displaystyle f_t and f s displaystyle f_s is given by    x i , t  ,  x j , s    k  x i , x j  k T  s , t   k  x i , x j  A s , t textstyle gamma x_i,t,x_j,skx_i,x_jk_Ts,tkx_i,x_jA_s,t . For vector valued functions f  H displaystyle fin mathcal H we can write   x i , x j   k  x i , x j  A displaystyle Gamma x_i,x_jkx_i,x_jA , where k is a scalar reproducing kernel, and A is a symmetric positive semi-definite T  T displaystyle Ttimes T matrix. Henceforth denote S  T   PSD matrices   R T  T displaystyle S_TtextPSD matricessubset mathbb R Ttimes T . This factorization property, separability, implies the input feature space representation does not vary by task. That is, there is no interaction between the input kernel and the task kernel. The structure on tasks is represented solely by A . Methods for non-separable kernels  is an current field of research. For the separable case, the representation theorem is reduced to f  x    i  1 N k  x , x i  A c i textstyle fxsum _i1Nkx,x_iAc_i . The model output on the training data is then KCA , where K is the n  n displaystyle ntimes n empirical kernel matrix with entries K i , j  k  x i , x j  textstyle K_i,jkx_i,x_j , and C is the n  T displaystyle ntimes T matrix of rows c i displaystyle c_i . With the separable kernel, equation 1 can be rewritten as min C  R n  T V  Y , K C A    t r  K C A C   displaystyle min _Cin mathbb R ntimes TVY,KCAlambda trKCACtop           P  where V is a weighted average of L applied entry-wise to Y and KCA . The weight is zero if Y i t displaystyle Y_it is a missing observation. Note the second term in P can be derived as follows  f  H 2    i  1 n k   , x i  A c i ,  j  1 n k   , x j  A c j  H   i , j  1 n  k   , x i  A c i , k   , x j  A c j  H bilinearity   i , j  1 n  k  x i , x j  A c i , c j  R T reproducing property   i , j  1 n k  x i , x j  c i  A c j  t r  K C A C   displaystyle beginalignedf_mathcal H2 leftlangle sum _i1nkcdot ,x_iAc_i,sum _j1nkcdot ,x_jAc_jrightrangle _mathcal H sum _i,j1nlangle kcdot ,x_iAc_i,kcdot ,x_jAc_jrangle _mathcal H textbilinearity sum _i,j1nlangle kx_i,x_jAc_i,c_jrangle _mathbb R T textreproducing property sum _i,j1nkx_i,x_jc_itop Ac_jtrKCACtop endaligned Known task structure  edit  Task structure representations  edit  There are three largely equivalent ways to represent task structure through a regularizer through an output metric, and through an output mapping. Regularizer      With the separable kernel, it can be shown below that   f   H 2   s , t  1 T A t , s   f s , f t  H k textstyle f_mathcal H2sum _s,t1TA_t,sdagger langle f_s,f_trangle _mathcal H_k , where A t , s  displaystyle A_t,sdagger  is the t , s displaystyle t,s element of the pseudoinverse of A displaystyle A , and H k displaystyle mathcal H_k is the RKHS based on the scalar kernel k displaystyle k , and f t  x    i  1 n k  x , x i  A t  c i textstyle f_txsum _i1nkx,x_iA_ttop c_i . This formulation shows that A t , s  displaystyle A_t,sdagger  controls the weight of the penalty associated with  f s , f t  H k textstyle langle f_s,f_trangle _mathcal H_k . Note that  f s , f t  H k textstyle langle f_s,f_trangle _mathcal H_k arises from   f t   H k   f t , f t  H k textstyle f_t_mathcal H_klangle f_t,f_trangle _mathcal H_k . Proof  f  H 2    i  1 n    x i , t i  ,   c i t i ,  j  1 n    x j , t j  ,   c j t j  H   i , j  1 n c i t i c j t j    x i , t i  ,  x j , t j     i , j  1 n  s , t  1 T c i t c j s k  x i , x j  A s , t   i , j  1 n k  x i , x j   c i , A c j  R T   i , j  1 n k  x i , x j   c i , A A  A c j  R T   i , j  1 n k  x i , x j   A c i , A  A c j  R T   i , j  1 n  s , t  1 T  A c i  t  A c j  s k  x i , x j  A s , t    s , t  1 T A s , t    i  1 n k  x i ,    A c i  t ,  j  1 n k  x j ,    A c j  s  H k   s , t  1 T A s , t   f t , f s  H k displaystyle beginalignedf_mathcal H2 leftlangle sum _i1ngamma x_i,t_i,cdot c_it_i,sum _j1ngamma x_j,t_j,cdot c_jt_jrightrangle _mathcal H sum _i,j1nc_it_ic_jt_jgamma x_i,t_i,x_j,t_j sum _i,j1nsum _s,t1Tc_itc_jskx_i,x_jA_s,t sum _i,j1nkx_i,x_jlangle c_i,Ac_jrangle _mathbb R T sum _i,j1nkx_i,x_jlangle c_i,AAdagger Ac_jrangle _mathbb R T sum _i,j1nkx_i,x_jlangle Ac_i,Adagger Ac_jrangle _mathbb R T sum _i,j1nsum _s,t1TAc_itAc_jskx_i,x_jA_s,tdagger  sum _s,t1TA_s,tdagger langle sum _i1nkx_i,cdot Ac_it,sum _j1nkx_j,cdot Ac_jsrangle _mathcal H_k sum _s,t1TA_s,tdagger langle f_t,f_srangle _mathcal H_kendaligned Output metric      an alternative output metric on Y T displaystyle mathcal YT can be induced by the inner product  y 1 , y 2     y 1 ,  y 2  R T displaystyle langle y_1,y_2rangle _Theta langle y_1,Theta y_2rangle _mathbb R T . With the squared loss there is an equivalence between the separable kernels k   ,   I T displaystyle kcdot ,cdot I_T under the alternative metric, and k   ,    displaystyle kcdot ,cdot Theta  , under the canonical metric. Output mapping      Outputs can be mapped as L  Y T  Y  displaystyle Lmathcal YTrightarrow mathcal tilde Y to a higher dimensional space to encode complex structures such as trees, graphs and strings. For linear maps L , with appropriate choice of separable kernel, it can be shown that A  L  L displaystyle ALtop L . Task structure examples  edit  Via the regularizer formulation, one can represent a variety of task structures easily. Letting A    I T       1 T 1 1  textstyle Adagger gamma I_Tgamma -lambda frac 1Tmathbf 1 mathbf 1 top  where I T displaystyle I_T is the T x T identity matrix, and 1 1  textstyle mathbf 1 mathbf 1 top  is the T x T matrix of ones is equivalent to letting  control the variance  t   f t  f    H k textstyle sum _tf_t-bar f_mathcal H_k of tasks from their mean 1 T  t f t textstyle frac 1Tsum _tf_t . For example, blood levels of some biomarker may be taken on T patients at n t displaystyle n_t time points during the course of a day and interest may lie in regularizing the variance of the predictions across patients. Letting A    I T       M displaystyle Adagger alpha I_Talpha -lambda M , where M t , s  1  G r  I  t , s  G r  displaystyle M_t,sfrac 1G_rmathbb I t,sin G_r is equivalent to letting  displaystyle alpha  control the variance measured with respect to a group mean  r  t  G r   f t  1  G r   s  G r  f s   displaystyle sum _rsum _tin G_rf_t-frac 1G_rsum _sin G_rf_s . Here  G r  displaystyle G_r the cardinality of group r, and I displaystyle mathbb I  is the indicator function. For example, people in different political parties groups might be regularized together with respect to predicting the favorability rating of a politician. Note that this penalty reduces to the first when all tasks are in the same group. Letting A    I T       L displaystyle Adagger delta I_Tdelta -lambda L , where L  D  M displaystyle LD-M is the L aplacian for the graph with adjacency matrix M giving pairwise similarities of tasks. This is equivalent to giving a larger penalty to the distance separating tasks t and s when they are more similar according to the weight M t , s displaystyle M_t,s , i.e.  displaystyle delta  regularizes  t , s   f t  f s   H k 2 M t , s displaystyle sum _t,sf_t-f_s_mathcal H_k2M_t,s . All of the above choices of A also induce the additional regularization term   t   f   H k 2 textstyle lambda sum _tf_mathcal H_k2 which penalizes complexity in f more broadly. Learning tasks together with their structure  edit  Learning problem P can be generalized to admit learning task matrix A as follows min C  R n  T , A  S  T V  Y , K C A    t r  K C A C    F  A  displaystyle min _Cin mathbb R ntimes T,Ain S_TVY,KCAlambda trKCACtop FA          Q  Choice of F  S  T  R  displaystyle FS_Trightarrow mathbb R _ must be designed to learn matrices A of a given type. See Special cases below. Optimization of Q  edit  Restricting to the case of convex losses and coercive penalties Ciliberto et al. have shown that although Q is not convex jointly in C and A, a related problem is jointly convex. Specifically on the convex set C    C , A   R n  T  S  T  R a n g e  C  K C   R a n g e  A   displaystyle mathcal CC,Ain mathbb R ntimes Ttimes S_TRangeCtop KCsubseteq RangeA , the equivalent problem min C , A  C V  Y , K C    t r  A  C  K C   F  A  displaystyle min _C,Ain mathcal CVY,KClambda trAdagger Ctop KCFA          R  is convex with the same minimum value. And if  C R , A R  displaystyle C_R,A_R is a minimizer for R then  C R A R  , A R  displaystyle C_RA_Rdagger ,A_R is a minimizer for Q . R may be solved by a barrier method on a closed set by introducing the following perturbation min C  R n  T , A  S  T V  Y , K C    t r  A   C  K C   2 I T    F  A  displaystyle min _Cin mathbb R ntimes T,Ain S_TVY,KClambda trAdagger Ctop KCdelta 2I_TFA          S  The perturbation via the barrier  2 t r  A   displaystyle delta 2trAdagger  forces the objective functions to be equal to   displaystyle infty  on the boundary of R n  T  S  T displaystyle Rntimes Ttimes S_T . S can be solved with a block coordinate descent method, alternating in C and A. This results in a sequence of minimizers  C m , A m  displaystyle C_m,A_m in S that converges to the solution in R as  m  0 displaystyle delta _mrightarrow 0 , and hence gives the solution to Q . Special cases  edit  Spectral penalties - Dinnuzo et al 16  suggested setting F as the Frobenius norm t r  A  A  displaystyle sqrt trAtop A . They optimized Q directly using block coordinate descent, not accounting for difficulties at the boundary of R n  T  S  T displaystyle mathbb R ntimes Ttimes S_T . Clustered tasks learning - Jacob et al 17  suggested to learn A in the setting where T tasks are organized in R disjoint clusters. In this case let E   0 , 1  T  R displaystyle Ein 0,1Ttimes R be the matrix with E t , r  I  task   t  group   r  displaystyle E_t,rmathbb I texttask tin textgroup r . Setting M  I  E  E T displaystyle MI-Edagger ET , and U  1 T 11  displaystyle Ufrac 1Tmathbf 11 top  , the task matrix A  displaystyle Adagger  can be parameterized as a function of M displaystyle M  A   M    M U   B  M  U     I  M  displaystyle Adagger Mepsilon _MUepsilon _BM-Uepsilon I-M , with terms that penalize the average, between clusters variance and within clusters variance respectively of the task predictions. M is not convex, but there is a convex relaxation S c   M  S  T  I  M  S  T  t r  M   r  displaystyle mathcal S_cMin S_TI-Min S_Tland trMr . In this formulation, F  A   I  A  M    A  M  S C   displaystyle FAmathbb I AMin AMin mathcal S_C . Generalizations  edit  Non-convex penalties - Penalties can be constructed such that A is constrained to be a graph Laplacian, or that A has low rank factorization. However these penalties are not convex, and the analysis of the barrier method proposed by Ciliberto et al. does not go through in these cases. Non-separable kernels - Separable kernels are limited, in particular they do not account for structures in the interaction space between the input and output domains jointly. Future work is needed to develop models for these kernels. Applications  edit  Spam filtering  edit  Using the principles of MTL, techniques for collaborative spam filtering that facilitates personalization have been proposed. In large scale open membership email systems, most users do not label enough messages for an individual local classifier to be effective, while the data is too noisy to be used for a global filter across all users. A hybrid globalindividual classifier can be effective at absorbing the influence of users who label emails very diligently from the general public. This can be accomplished while still providing sufficient quality to users with few labeled instances. 18  Web search  edit  Using boosted decision trees , one can enable implicit data sharing and regularization. This learning method can be used on web-search ranking data sets. One example is to use ranking data sets from several countries. Here, multitask learning is particularly helpful as data sets from different countries vary largely in size because of the cost of editorial judgments. It has been demonstrated that learning various tasks jointly can lead to significant improvements in performance with surprising reliability. 19  RoboEarth  edit  In order to facilitate transfer of knowledge, IT infrastructure is being developed. One such project, RoboEarth, aims to set up an open source internet database that can be accessed and continually updated from around the world. The goal is to facilitate a cloud-based interactive knowledge base, accessible to technology companies and academic institutions, which can enhance the sensing, acting and learning capabilities of robots and other artificial intelligence agents. 20  Software package  edit  The Multi-Task Learning via StructurAl Regularization MALSAR Matlab package 21  implements the following multi-task learning algorithms Mean-Regularized Multi-Task Learning 22  23  Multi-Task Learning with Joint Feature Selection 24  Robust Multi-Task Feature Learning 25  Trace-Norm Regularized Multi-Task Learning 26  Alternating Structural Optimization 27  28  Incoherent Low-Rank and Sparse Learning 29  Robust Low-Rank Multi-Task Learning Clustered Multi-Task Learning 30  31  Multi-Task Learning with Graph Structures See also  edit  Artificial intelligence Artificial neural network Automated machine learning AutoML Evolutionary computation General game playing Human-based genetic algorithm Kernel methods for vector output Machine learning Multitask optimization Robot learning Transfer learning References  edit   Baxter, J. 2000. A model of inductive bias learning Journal of Artificial Intelligence Research 12149--198, On-line paper  Thrun, S. 1996. Is learning the n-th thing any easier than learning the first. In Advances in Neural Information Processing Systems 8, pp. 640--646. MIT Press. Paper at Citeseer  a b Caruana, R. 1997. Multi-task learning PDF . Machine Learning . 28  4175. doi  10.1023A1007379606734 . .mw-parser-output cite.citationfont-styleinherit.mw-parser-output .citation qquotes.mw-parser-output .citation .cs1-lock-free abackgroundurlupload.wikimedia.orgwikipediacommonsthumb665Lock-green.svg9px-Lock-green.svg.pngno-repeatbackground-positionright .1em center.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration abackgroundurlupload.wikimedia.orgwikipediacommonsthumbdd6Lock-gray-alt-2.svg9px-Lock-gray-alt-2.svg.pngno-repeatbackground-positionright .1em center.mw-parser-output .citation .cs1-lock-subscription abackgroundurlupload.wikimedia.orgwikipediacommonsthumbaaaLock-red-alt-2.svg9px-Lock-red-alt-2.svg.pngno-repeatbackground-positionright .1em center.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registrationcolor555.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration spanborder-bottom1px dottedcursorhelp.mw-parser-output .cs1-ws-icon abackgroundurlupload.wikimedia.orgwikipediacommonsthumb44cWikisource-logo.svg12px-Wikisource-logo.svg.pngno-repeatbackground-positionright .1em center.mw-parser-output code.cs1-codecolorinheritbackgroundinheritborderinheritpaddinginherit.mw-parser-output .cs1-hidden-errordisplaynonefont-size100.mw-parser-output .cs1-visible-errorfont-size100.mw-parser-output .cs1-maintdisplaynonecolor33aa33margin-left0.3em.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-formatfont-s ize95.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-leftpadding-left0.2em.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-rightpadding-right0.2em  Suddarth, S., Kergosien, Y. 1990. Rule-injection hints as a means of improving network performance and learning time. EURASIP Workshop. Neural Networks pp. 120-129. Lecture Notes in Computer Science. Springer.  Abu-Mostafa, Y. S. 1990. Learning from hints in neural networks. Journal of Complexity . 6 2 192198. doi  10.10160885-064x9090006-y .  a b Weinberger, Kilian. Multi-task Learning .  a b c Ciliberto, C. 2015. Convex Learning of Multiple Tasks and their Structure. arXiv  1504.03101  cs.LG .  a b c d Hajiramezanali, E.  Dadaneh, S. Z.  Karbalayghareh, A.  Zhou, Z.  Qian, X. Bayesian multi-domain learning for cancer subtype discovery from next-generation sequencing count data. 32nd Conference on Neural Information Processing Systems NIPS 2018, Montral, Canada. httpsarxiv.orgpdf1810.09433.pdf  a b Romera-Paredes, B., Argyriou, A., Bianchi-Berthouze, N.,  Pontil, M., 2012 Exploiting Unrelated Tasks in Multi-Task Learning. httpjmlr.csail.mit.eduproceedingspapersv22romera12romera12.pdf  Kumar, A.,  Daume III, H., 2012 Learning Task Grouping and Overlap in Multi-Task Learning. httpicml.cc2012papers690.pdf  Jawanpuria, P.,  Saketha Nath, J., 2012 A Convex Feature Learning Formulation for Latent Task Structure Discovery. httpicml.cc2012papers90.pdf  Zweig, A.  Weinshall, D. Hierarchical Regularization Cascade for Joint Learning. Proceedings of 30th International Conference on Machine Learning ICML, Atlanta GA, June 2013. httpwww.cs.huji.ac.ildaphnapapersZweig_ICML2013.pdf  Szegedy, C. 2014. Going Deeper with Convolutions . Computer Vision and Pattern Recognition CVPR, 2015 IEEE Conference on . pp.  19. arXiv  1409.4842 . doi  10.1109CVPR.2015.7298594 . ISBN   978-1-4673-6964-0 .  Roig, Gemma. Deep Learning Overview PDF .  Zweig, A.  Chechik, G. Group online adaptive learning. Machine Learning, DOI 10.1007s10994-017- 5661-5, August 2017. httprdcu.beuFSv  Dinuzzo, Francesco 2011. Learning output kernels with block coordinate descent PDF . Proceedings of the 28th International Conference on Machine Learning ICML-11 .  Jacob, Laurent 2009. Clustered multi-task learning A convex formulation. Advances in Neural Information Processing Systems .  Attenberg, J., Weinberger, K.,  Dasgupta, A. Collaborative Email-Spam Filtering with the Hashing-Trick. httpwww.cse.wustl.edukilianpapersceas2009-paper-11.pdf  Chappelle, O., Shivaswamy, P.,  Vadrevu, S. Multi-Task Learning for Boosting with Application to Web Search Ranking. httpwww.cse.wustl.edukilianpapersmultiboost2010.pdf  Description of RoboEarth Project  Zhou, J., Chen, J. and Ye, J. MALSAR Multi-tAsk Learning via StructurAl Regularization. Arizona State University, 2012. httpwww.public.asu.edujye02SoftwareMALSAR . On-line manual  Evgeniou, T.,  Pontil, M. 2004. Regularized multitask learning . Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining pp. 109117.  Evgeniou, T. Micchelli, C. Pontil, M. 2005. Learning multiple tasks with kernel methods PDF . Journal of Machine Learning Research . 6  615.  Argyriou, A. Evgeniou, T. Pontil, M. 2008a. Convex multi-task feature learning. Machine Learning . 73 3 243272. doi  10.1007s10994-007-5040-8 .  Chen, J., Zhou, J.,  Ye, J. 2011. Integrating low-rank and group-sparse structures for robust multi-task learning . Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining.  Ji, S.,  Ye, J. 2009. An accelerated gradient method for trace norm minimization . Proceedings of the 26th Annual International Conference on Machine Learning pp. 457464.  Ando, R. Zhang, T. 2005. A framework for learning predictive structures from multiple tasks and unlabeled data PDF . The Journal of Machine Learning Research . 6  18171853.  Chen, J., Tang, L., Liu, J.,  Ye, J. 2009. A convex formulation for learning shared structures from multiple tasks . Proceedings of the 26th Annual International Conference on Machine Learning pp. 137144.  Chen, J., Liu, J.,  Ye, J. 2010. Learning incoherent sparse and low-rank patterns from multiple tasks . Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining pp. 11791188.  Jacob, L., Bach, F.,  Vert, J. 2008. Clustered multi-task learning A convex formulation . Advances in Neural Information Processing Systems 2008  Zhou, J., Chen, J.,  Ye, J. 2011. Clustered multi-task learning via alternating structure optimization . Advances in Neural Information Processing Systems. External links  edit  The Biosignals Intelligence Group at UIUC Washington University at St. Louis Depart. of Computer Science Software  edit  The Multi-Task Learning via Structural Regularization Package Online Multi-Task Learning Toolkit OMT A general-purpose online multi-task learning toolkit based on conditional random field models and stochastic gradient descent training  C , .NET  Retrieved from  httpsen.wikipedia.orgwindex.phptitleMulti-task_learning oldid912606912  Categories  Machine learning Hidden categories Articles with short description
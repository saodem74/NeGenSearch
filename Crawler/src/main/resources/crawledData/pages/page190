Software quality From Wikipedia, the free encyclopedia Jump to navigation Jump to search In the context of software engineering , software quality refers to two related but distinct notions Software functional quality reflects how well it complies with or conforms to a given design, based on functional requirements or specifications. That attribute can also be described as the fitness for purpose of a piece of software or how it compares to competitors in the marketplace as a worthwhile product . 1  It is the degree to which the correct software was produced. Software structural quality refers to how it meets non-functional requirements that support the delivery of the functional requirements, such as robustness or maintainability. It has a lot more to do with the degree to which the software works as needed . Many aspects of structural quality can be evaluated only statically through the analysis of the software inner structure, its source code, at the unit level, the technology level and the system level, which is in effect how its architecture adheres to sound principles of software architecture outlined in a paper on the topic by OMG. 2  But some structural qualities, such as usability , can be assessed only dynamically users or others acting in their behalf interact with the software or, at least, some prototype or partial implementation even the interaction with a mock version made in cardboard represents a dynamic test because such version can be considered a prototype. Other aspects, such as reliability, might involve not only the software but also the underlying hardware, therefore, i t can be assessed both statically and dynamically  stress test . Functional quality is typically assessed dynamically but it is also possible to use static tests such as software reviews . Historically, the structure, classification and terminology of attributes and metrics applicable to software quality management have been derived or extracted from the ISO 9126-3 and the subsequent ISO 250002005 3  quality model, also known as SQuaRE. 4  Based on these models, the Consortium for IT Software Quality CISQ has defined five major desirable structural characteristics needed for a piece of software to provide business value  Reliability, Efficiency, Security, Maintainability and adequate Size. Software quality measurement quantifies to what extent a software program or system rates along each of these five dimensions. An aggregated measure of software quality can be computed through a qualitative or a quantitative scoring scheme or a mix of both and then a weighting system reflecting the priorities. This view of software quality being positioned on a linear continuum is supplemented by the analysis of critical programming errors that under specific circumstances can lead to catastrophic outages or performance degradations that make a given system unsuitable for use regardless of rating based on aggregated measurements. Such programming errors found at the system level represent up to 90 of production issues, whilst at the unit-level, ev en if far more numerous, programming errors account for less than 10 of production issues. As a consequence, code quality without the context of the whole system, as W. Edwards Deming described it, has limited value. To view, explore, analyze, and communicate software quality measurements, concepts and techniques of information visualization provide visual, interactive means useful, in particular, if several software quality measures have to be related to each other or to components of a software or system. For example, software maps represent a specialized approach that can express and combine information about software development, software quality, and system dynamics. 5  Contents 1 Motivation 2 Definitions 2.1 Kitchenham, Pfleeger, and Garvins five perspectives on quality 2.2 Software quality according to Deming 2.3 Software quality according to Feigenbaum 2.4 Software quality according to Juran 2.5 CISQs quality model 3 Alternative approaches 4 Measurement 4.1 Introduction 4.2 Code-based analysis 4.3 Reliability 4.4 Efficiency 4.5 Security 4.6 Maintainability 4.7 Size 4.8 Identifying critical programming errors 4.9 Operationalized quality models 5 See also 6 Further reading 7 References 8 External links Motivation  edit  A science is as mature as its measurement tools, Louis Pasteur in Ebert  Dumke , p.  91. Measuring software quality is motivated by at least two reasons Risk Management Software failure has caused more than inconvenience. Software errors have caused human fatalities. The causes have ranged from poorly designed user interfaces to direct programming errors . An example of a programming error that led to multiple deaths is discussed in Dr. Levesons paper. 6  This resulted in requirements for the development of some types of software, particularly and historically for software embedded in medical and other devices that regulate critical infrastructures Engineers who write embedded software see Java programs stalling for one third of a second to perform garbage collection and update the user interface, and they envision airplanes falling out of the sky.. 7  In the United States, within the Federal Aviation Administration FAA, the FAA Aircraft Certification Service provides software programs, policy, guidance and training, focus on software and Complex Electronic Hardware that has an effect on the airborne product a product is an aircraft, an engine, or a propeller. 8  Cost Management As in any other fields of engineering, an application with good structural software quality costs less to maintain and is easier to understand and change in response to pressing business needs. Industry data demonstrate that poor application structural quality in core business applications such as enterprise resource planning ERP, customer relationship management CRM or large transaction processing systems in financial services results in cost and schedule overruns and creates waste in the form of rework up to 45 of development time in some organizations 9  . Moreover, poor structural quality is strongly correlated with high-impact business disruptions due to corrupted data, application outages, security breaches, and performance problems. However, the distinction between measuring and improving software quality in an embedded system with emphasis on risk management and software quality in business software with emphasis on cost and maintainability management is becoming somewhat irrelevant. Embedded systems now often include a user interface and their designers are as much concerned with issues affecting usa bility and user productivity as their counterparts who focus on business applications. The latter are in turn looking at ERP or CRM system as a corporate nervous system whose uptime and performance are vital to the well-being of the enterprise. This convergence is most visible in mobile computing a user who accesses an ERP application on their smartphone is depending on the quality of software across all types of software layers. Both types of software now use multi-layered technology stacks and complex architecture so software quality analysis and measurement have to be managed in a comprehensive and consistent manner, decoupled from the softwares ultimate purpose or use. In both cases, engineers and management need to be able to make rational decisions based on measurement and fact-based analysis in adherence to the precept In God we trust. All others bring data . mis-attributed to W. Edwards Deming and others. Definitions  edit  There are many different definitions of quality. For some it is the capability of a software product to conform to requirements. ISOIEC 9001, 10  commented by 11   while for others it can be synonymous with customer value Highsmith, 2002 or even defect level. The first definition of quality History remembers is from Shewhart in the beginning of 20th century There are two common aspects of quality one of them has to do with the consideration of the quality of a thing as an objective reality independent of the existence of man. The other has to do with what we think, feel or sense as a result of the objective reality. In other words, there is a subjective side of quality. Shewhart 12   Kitchenham, Pfleeger, and Garvins five perspectives on quality  edit  Kitchenham and Pfleeger, 13  further reporting the teachings of David Garvin, 14  identify five different perspectives on quality The transcendental perspective deals with the metaphysical aspect of quality. In this view of quality, it is something toward which we strive as an ideal, but may never implement completely. 13  It can hardly be defined, but is similar to what a federal judge once commented about obscenity I know it when I see it. 15  The user perspective is concerned with the appropriateness of the product for a given context of use. Whereas the transcendental view is ethereal, the user view is more concrete, grounded in the product characteristics that meet users needs. 13  The manufacturing perspective represents quality as conformance to requirements. This aspect of quality is stressed by standards such as ISO 9001, which defines quality as the degree to which a set of inherent characteristics fulfills requirements ISOIEC 9001 10  . The product perspective implies that quality can be appreciated by measuring the inherent characteristics of the product. The final perspective of quality is value-based. This perspective recognises that the different perspectives of quality may have different importance, or value, to various stakeholders. Software quality according to Deming  edit  .mw-parser-output .templatequoteoverflowhiddenmargin1em 0padding0 40px.mw-parser-output .templatequote .templatequoteciteline-height1.5emtext-alignleftpadding-left1.6emmargin-top0 The problem inherent in attempts to define the quality of a product, almost any product, were stated by the master Walter A. Shewhart. The difficulty in defining quality is to translate future needs of the user into measurable characteristics, so that a product can be designed and turned out to give satisfaction at a price that the user will pay. This is not easy, and as soon a s one feels fairly successful in the endeavor, he finds that the needs of the consumer have changed, competitors have moved in, etc. 16   W. Edwards Deming Software quality according to Feigenbaum  edit  Quality is a customer determination, not an engineers determination, not a marketing determination, nor a general management determination. It is based on the customers actual experience with the product or service, measured against his or her requirements -- stated or unstated, conscious or merely sensed, technically operational or entirely subjective -- and always represent ing a moving target in a competitive market. 17  Software quality according to Juran  edit  The word quality has multiple meanings. Two of these meanings dominate the use of the word 1. Quality consists of those product features which meet the need of customers and thereby provide product satisfaction. 2. Quality consists of freedom from deficiencies. Nevertheless, in a handbook such as this it is convenient to standardize on a short definition of the word quality as fitness for use. 18  CISQs quality model  edit  Even though quality is a perceptual, conditional and somewhat subjective attribute and may be understood differently by different people as noted in the article on quality in business , software structural quality characteristics have been clearly defined by the Consortium for IT Software Quality CISQ. Under the guidance of Bill Curtis , co-author of the Capability Maturity Model framework and CISQs first Director and Capers Jones , CISQs Distinguished Advisor, CISQ has defined five major desirable characteristics of a piece of software needed to provide business value . 19  In the House of Quality model, these are Whats that need to be achieved Reliability An attribute of resiliency and structural solidity. Reliability measures the level of risk and the likelihood of potential application failures. It also measures the defects injected due to modifications made to the software its stability as termed by ISO. The goal for checking and monitoring Reliability is to reduce and prevent application downtime, application outages and errors that directly affect users, and enhance the image of IT and its impact on a companys business performance. Efficiency The source code and software architecture attributes are the elements that ensure high performance once the application is in run-time mode. Efficiency is especially important for applications in high execution speed environments such as algorithmic or transactional processing where performance and scalability are paramount. An analysis of source code efficiency and scalability provides a clear picture of the latent business risks and the harm they can cause to customer satisfaction due to response-time degradation. Security A measure of the likelihood of potential security breaches due to poor coding practices and architecture. This quantifies the risk of encountering critical vulnerabilities that damage the business. 20  Maintainability Maintainability includes the notion of adaptability, portability and transferability from one development team to another. Measuring and monitoring maintainability is a must for mission-critical applications where change is driven by tight time-to-market schedules and where it is important for IT to remain responsive to business-driven changes. It is also essential to keep ma intenance costs under control. Size While not a quality attribute per se, the sizing of source code is a software characteristic that obviously impacts maintainability. Combined with the above quality characteristics, software size can be used to assess the amount of work produced and to be done by teams, as well as their productivity through correlation with time-sheet data, and other SDLC -related metrics. Software functional quality is defined as conformance to explicitly stated functional requirements, identified for example using Voice of the Customer analysis part of the Design for Six Sigma toolkit andor documented through use cases  and the level of satisfaction experienced by end-users. The latter is referred as to as usability and is concerned with how intuitive and responsive the user interface is, how easily simple and complex operations can be performed, and how useful error messages are. Typically, software testing practices and tools ensure that a piece of software behaves in compliance with the original design, planned user experience and desired testability , i.e. a piece of softwares disposition to support acceptance criteria. The dual structuralfunctional dimension of software quality is consistent with the model proposed in Steve McConnell s Code Complete which divides software characteristics into two pieces internal and external quality characteristics. External quality characteristics are those parts of a product that face its users, where internal quality characteristics are those that do not. 21  Alternative approaches  edit  One of the challenges in defining quality is that everyone feels they understand it 22  and other definitions of software quality could be based on extending the various descriptions of the concept of quality used in business. Dr. Tom DeMarco has proposed that a products quality is a function of how much it changes the world for the better. 23  This can be interpreted as meaning that functional quality and user satisfaction are more important than structural quality in determining software quality. Another definition, coined by Gerald Weinberg in Quality Software Management Systems Thinking, is Quality is value to some person. 24  25  This definition stresses that quality is inherently subjectivedifferent people will experience the quality of the same software differently. One strength of this definition is the questions it invites software teams to consider, such as Who are the people we want to value our software and What will be valuable to them. Measurement  edit  Although the concepts presented in this section are applicable to both structural and functional software quality, measurement of the latter is essentially performed through testing see main article Software testing . Introduction  edit  Relationship between software desirable characteristics right and measurable attributes left. Software quality measurement is about quantifying to what extent a system or software possesses desirable characteristics. This can be performed through qualitative or quantitative means or a mix of both. In both cases, for each desirable characteristic, there are a set of measurable attributes the existence of which in a piece of software or system tend to be correlated and as sociated with this characteristic. For example, an attribute associated with portability is the number of target-dependent statements in a program. More precisely, using the Quality Function Deployment approach, these measurable attributes are the hows that need to be enforced to enable the whats in the Software Quality definition above. The structure, classification and terminology of attributes and metrics applicable to software quality management have been derived or extracted from the ISO 9126-3 and the subsequent ISOIEC 250002005 quality model. The main focus is on internal structural quality. Subcategories have been created to handle specific areas like business application architecture and technical characteristics such as data access and manipulation or the notion of transactions. The dependence tree between software quality characteristics and their measurable attributes is represented in the diagram on the right, where each of the 5 characteristics that matter for the user right or owner of the business system depends on measurable attributes left Application Architecture Practices Coding Practices Application Complexity Documentation Portability Technical and Functional Volume Correlations between programming errors and production defects unveil that basic code errors account for 92 of the total errors in the source code. These numerous code-level issues eventually count for only 10 of the defects in production. Bad software engineering practices at the architecture levels account for only 8 of total defects, but consume over half the effort spent on fixing problems, and lead to 90 of the serious reliability, security, and efficiency issues in production. 26  Code-based analysis  edit  Many of the existing software measures count structural elements of the application that result from parsing the source code for such individual instructions Park, 1992, 27  tokens Halstead, 1977, 28  control structures McCabe, 1976, and objects Chidamber  Kemerer, 1994. 29  Software quality measurement is about quantifying to what extent a system or software rates along these dimensions. The analysis can be performed using a qualitative or quantitative approach or a mix of both to provide an aggregate view using for example weighted averages that reflect relative importance between the factors being measured. This view of software quality on a linear continuum has to be supplemented by the identification of discrete Critical Programming Errors . These vulnerabilities may not fail a test case, but they are the result of bad practices that under specific circumstances can lead to catastrophic outages, performance degradations, security breaches, corrupted data, and myriad other problems Nygard, 2007 30  that make a given system de facto unsuitable for use regardless of its rating based on aggregated measurements. A well-known example of vulnerability is the Common Weakness Enumeration , 31  a repository of vulnerabilities in the source code that make applications exposed to security breaches. The measurement of critical application characteristics involves measuring structural attributes of the applications architecture, coding, and in-line documentation, as displayed in the picture above. Thus, each characteristic is affected by attributes at numerous levels of abstraction in the application and all of which must be included calculating the characteristics measur e if it is to be a valuable predictor of quality outcomes that affect the business. The layered approach to calculating characteristic measures displayed in the figure above was first proposed by Boehm and his colleagues at TRW Boehm, 1978 32  and is the approach taken in the ISO 9126 and 25000 series standards. These attributes can be measured from the parsed results of a static analysis of the application source code. Even dynamic characteristics of applications such as reliability and performance efficiency have their causal roots in the static structure of the application. Structural quality analysis and measurement is performed through the analysis of the source code , the architecture , software framework , database schema in relationship to principles and standards that together define the conceptual and logical architecture of a system. This is distinct from the basic, local, component-level code analysis typically performed by development tools which are mostly concerned with implementation considerations and are crucial during debugging and testing activities. Reliability  edit  The root causes of poor reliability are found in a combination of non-compliance with good architectural and coding practices. This non-compliance can be detected by measuring the static quality attributes of an application. Assessing the static attributes underlying an applications reliability provides an estimate of the level of business risk and the likelihood of potential application failures and defects the application will experience when placed in operation. Assessing reliability requires checks of at least the following software engineering best practices and technical attributes Application Architecture Practices Coding Practices Complexity of algorithms Complexity of programming practices Compliance with Object-Oriented and Structured Programming best practices when applicable Component or pattern re-use ratio Dirty programming Error  Exception handling for all layers - GUI, Logic  Data Multi-layer design compliance Resource bounds management Software avoids patterns that will lead to unexpected behaviors Software manages data integrity and consistency Transaction complexity level Depending on the application architecture and the third-party components used such as external libraries or frameworks, custom checks should be defined along the lines drawn by the above list of best practices to ensure a better assessment of the reliability of the delivered software. Efficiency  edit  As with Reliability, the causes of performance inefficiency are often found in violations of good architectural and coding practice which can be detected by measuring the static quality attributes of an application. These static attributes predict potential operational performance bottlenecks and future scalability problems, especially for applications requiring high execution speed for handling complex algorithms or huge volumes of data. Assessing performance efficiency requires checking at least the following software engineering best practices and technical attributes Application Architecture Practices Appropriate interactions with expensive andor remote resources Data access performance and data management Memory, network and disk space management Coding Practices Compliance with Object-Oriented and Structured Programming best practices as appropriate Compliance with SQL programming best practices Security  edit  Most security vulnerabilities result from poor coding and architectural practices such as SQL injection or cross-site scripting. These are well documented in lists maintained by CWE, 33  and the SEIComputer Emergency Center CERT at Carnegie Mellon University. Assessing security requires at least checking the following software engineering best practices and technical attributes Application Architecture Practices Multi-layer design compliance Security best practices Input Validation, SQL Injection, Cross-Site Scripting, etc. 34   Programming Practices code level Error  Exception handling Security best practices system functions access, access control to programs Maintainability  edit  Maintainability includes concepts of modularity, understandability, changeability, testability, reusability, and transferability from one development team to another. These do not take the form of critical issues at the code level. Rather, poor maintainability is typically the result of thousands of minor violations with best practices in documentation, complexity avoidance str ategy, and basic programming practices that make the difference between clean and easy-to-read code vs. unorganized and difficult-to-read code. 35  Assessing maintainability requires checking the following software engineering best practices and technical attributes Application Architecture Practices Architecture, Programs and Code documentation embedded in source code Code readability Complexity level of transactions Complexity of algorithms Complexity of programming practices Compliance with Object-Oriented and Structured Programming best practices when applicable Component or pattern re-use ratio Controlled level of dynamic coding Coupling ratio Dirty programming Documentation Hardware, OS, middleware, software components and database independence Multi-layer design compliance Portability Programming Practices code level Reduced duplicate code and functions Source code file organization cleanliness Maintainability is closely related to Ward Cunninghams concept of technical debt , which is an expression of the costs resulting of a lack of maintainability. Reasons for why maintainability is low can be classified as reckless vs. prudent and deliberate vs. inadvertent, 36  and often have their origin in developers inability, lack of time and goals, their carelessness and discrepancies in the creation cost of and benefits from documentation and, in particular, maintainable source code . 37  Size  edit  Measuring software size requires that the whole source code be correctly gathered, including database structure scripts, data manipulation source code, component headers, configuration files etc. There are essentially two types of software sizes to be measured, the technical size footprint and the functional size There are several software technical sizing methods that have been widely described. The most common technical sizing method is number of Lines of Code LOC per technology, number of files, functions, classes, tables, etc., from which backfiring Function Points can be computed The most common for measuring functional size is function point analysis. Function point analysis measures the size of the software deliverable from a users perspective. Function point sizing is done based on user requirements and provides an accurate representation of both size for the developerestimator and value functionality to be delivered and reflects the business functionality being delivered to the customer. The method includes the identification and weighting of user recognizable inputs, outputs and data stores. The size value is then available for use in conjunction with numerous measures to quantify and to evaluate software delivery and performance development cost per function point delivered defects per function point function points per staff month.. The function point analysis sizing standard is supported by the International Function Point Users Group IFPUG. It can be applied early in the software development life-cycle and it is not dependent on lines of code like the somewhat inaccurate Backfiring method. The method is technology agnostic and can be used for comparative analysis across organizations and across industr ies. Since the inception of Function Point Analysis, several variations have evolved and the family of functional sizing techniques has broadened to include such sizing measures as COSMIC, NESMA, Use Case Points, FP Lite, Early and Quick FPs, and most recently Story Points. However, Function Points has a history of statistical accuracy, and has been used as a common unit of work mea surement in numerous application development management ADM or outsourcing engagements, serving as the currency by which services are delivered and performance is measured. One common limitation to the Function Point methodology is that it is a manual process and therefore it can be labor-intensive and costly in large scale initiatives such as application development or outsourcing engagements. This negative aspect of applying the methodology may be what motivated industry IT leaders to form the Consortium for IT Software Quality focused on introd ucing a computable metrics standard for automating the measuring of software size while the IFPUG keep promoting a manual approach as most of its activity rely on FP counters certifications. CISQ announced the availability of its first metric standard, Automated Function Points,to the CISQ membership, in CISQ Technical. These recommendations have been developed in OMGs Request for Comment format and submitted to OMGs process for standardization.  citation needed  Identifying critical programming errors  edit  Critical Programming Errors are specific architectural andor coding bad practices that result in the highest, immediate or long term, business disruption risk. These are quite often technology-related and depend heavily on the context, business objectives and risks. Some may consider respect for naming conventions while others  those preparing the ground for a knowledge transfer for example  will consider it as absolutely critical. Critical Programming Errors can also be classified per CISQ Characteristics. Basic example below Reliability Avoid software patterns that will lead to unexpected behavior  Uninitialized variable , null pointers, etc. Methods, procedures and functions doing Insert, Update, Delete, Create Table or Select must include error management Multi-thread functions should be made thread safe, for instance servlets or struts action classes must not have instancenon-final static fields Efficiency Ensure centralization of client requests incoming and data to reduce network traffic Avoid SQL queries that dont use an index against large tables in a loop Security Avoid fields in servlet classes that are not final static Avoid data access without including error management Check control return codes and implement error handling mechanisms Ensure input validation to avoid cross-site scripting flaws or SQL injections flaws Maintainability Deep inheritance trees and nesting should be avoided to improve comprehensibility Modules should be loosely coupled fanout, intermediaries to avoid propagation of modifications Enforce homogeneous naming conventions Operationalized quality models  edit  Newer proposals for quality models such as Squale and Quamoco 38  propagate a direct integration of the definition of quality attributes and measurement. By breaking down quality attributes or even defining additional layers, the complex, abstract quality attributes such as reliability or maintainability become more manageable and measurable. Those quality models have been applied in industrial contexts but have not received widespread ado ption. See also  edit  ISOIEC 9126 Software Process Improvement and Capability Determination - ISOIEC 15504 Software testing Quality  quality control , total quality management . Software quality assurance Programming style Coding conventions Software architecture Software quality control Software metrics Cyclomatic complexity Cohesion and Coupling Software reusability Software standard Accessibility Availability Dependability Testability Security Security engineering Computer bug Best coding practices Anomaly in software Further reading  edit  International Organization for Standardization. Software EngineeringProduct QualityPart 1 Quality Model . ISO, Geneva, Switzerland, 2001. ISOIEC 9126-12001E. Spinellis, Diomidis 2006-04-04. Code quality the open source perspective . Upper Saddle River, New Jersey, US Addison-Wesley Professional. ISBN   978-0-321-16607-4 . .mw-parser-output cite.citationfont-styleinherit.mw-parser-output .citation qquotes.mw-parser-output .citation .cs1-lock-free abackgroundurlupload.wikimedia.orgwikipediacommonsthumb665Lock-green.svg9px-Lock-green.svg.pngno-repeatbackground-positionright .1em center.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration abackgroundurlupload.wikimedia.orgwikipediacommonsthumbdd6Lock-gray-alt-2.svg9px-Lock-gray-alt-2.svg.pngno-repeatbackground-positionright .1em center.mw-parser-output .citation .cs1-lock-subscription abackgroundurlupload.wikimedia.orgwikipediacommonsthumbaaaLock-red-alt-2.svg9px-Lock-red-alt-2.svg.pngno-repeatbackground-positionright .1em ce nter.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registrationcolor555.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration spanborder-bottom1px dottedcursorhelp.mw-parser-output .cs1-ws-icon abackgroundurlupload.wikimedia.orgwikipediacommonsthumb44cWikisource-logo.svg12px-Wikisource-logo.svg.pngno-repeatbackground-positionright .1em center.mw-parser-output code.cs1-codecolorinheritbackgroundinheritborderinheritpaddinginherit.mw-parser-output .cs1-hidden-errordisplaynonefont-size100.mw-parser-output .cs1-visible-errorfont-size100.mw-parser-output .cs1-maintdisplaynonecolor33aa33margin-left0.3em.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-outpu t .cs1-formatfont-size95.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-leftpadding-left0.2em.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-rightpadding-right0.2em Ho-Won Jung, Seung-Gweon Kim, and Chang-Sin Chung. Measuring software product quality A survey of ISOIEC 9126 . IEEE Software , 2151013, SeptemberOctober 2004. Stephen H. Kan. Metrics and Models in Software Quality Engineering . Addison-Wesley, Boston, MA, second edition, 2002. Omar Alshathry, Helge Janicke, Optimizing Software Quality Assurance, compsacw, pp.  8792, 2010 IEEE 34th Annual Computer Software and Applications Conference Workshops, 2010. Robert L. Glass. Building Quality Software . Prentice Hall, Upper Saddle River, NJ, 1992. Roland Petrasch,  The Definition of Software Quality A Practical Approach , ISSRE, 1999 Capers Jones and Olivier Bonsignour, The Economics of Software Quality, Addison-Wesley Professional, 1st edition, December 31, 2011, ISBN   978-0-13-258220-9 Measuring Software Product Quality the ISO 25000 Series and CMMI SEI site MSQF - A measurement based software quality framework Cornell University Library Stefan Wagner. Software Product Quality Control . Springer, 2013. Girish Suryanarayana, Software Process versus Design Quality Tug of War 39  Association of Maritime Managers in Information Technology  Communications AMMITEC. Maritime Software Quality Guidelines . September 2017 References  edit  Notes  Pressman, Roger S. 2005. Software Engineering A Practitioners Approach Sixth International ed.. McGraw-Hill Education. p.  388. ISBN   0071267824 .  How to Deliver Resilient, Secure, Efficient, and Easily Changed IT Systems in Line with CISQ Recommendations PDF . Archived PDF from the original on 2013-12-28 . Retrieved 2013-10-18 . Cite uses deprecated parameter deadurl  help   ISO 250002005 PDF . Archived PDF from the original on 2013-04-14 . Retrieved 2013-10-18 . Cite uses deprecated parameter deadurl  help   ISOIEC 250102011 . ISO. Archived from the original on 14 March 2016 . Retrieved 14 March 2016 . Cite uses deprecated parameter deadurl  help   J. Bohnet, J. Dllner Archived 2014-04-27 at the Wayback Machine , Monitoring Code Quality and Development Activity by Software Maps. Proceedings of the IEEE ACM ICSE Workshop on Managing Technical Debt, pp. 9-16, 2011.  Medical Devices The Therac-25 Archived 2008-02-16 at the Wayback Machine , Nancy Leveson, University of Washington  Embedded Software Archived 2010-07-05 at the Wayback Machine , Edward A. Lee, To appear in Advances in Computers M. Zelkowitz, editor, Vol. 56, Academic Press, London, 2002, Revised from UCB ERL Memorandum M0126 University of California, Berkeley, CA 94720, USA, November 1, 2001  Aircraft Certification Software and Airborne Electronic Hardware . Archived from the original on 4 October 2014 . Retrieved 28 September 2014 . Cite uses deprecated parameter deadurl  help   Improving Quality Through Better Requirements Slideshow Archived 2012-03-26 at the Wayback Machine , Dr. Ralph R. Young, 24012004, Northrop Grumman Information Technology  a b International Organization for Standardization, ISOIEC 9001 Quality management systems -- Requirements, 1999.  International Organization for Standardization, ISOIEC 24765 Systems and software engineering  Vocabulary, 2010.  W. A. Shewhart, Economic control of quality of manufactured product. Van Nostrand, 1931.  a b c B. Kitchenham and S. Pfleeger, Software quality the elusive target, IEEE Software, vol. 13, no. 1, pp. 1221, 1996.  D. A. Garvin, Managing Quality - the strategic and competitive edge. New York, NY Free Press u.a., 1988.  S. H. Kan, Metrics and Models in Software Quality Engineering, 2nd ed. Boston, MA, USA Addison-Wesley Longman Publishing Co., Inc., 2002.  W. E. Deming, Out of the crisis quality, productivity and competitive position. Cambridge University Press, 1988.  A. V. Feigenbaum, Total Quality Control, McGraw-Hill, 1983.  J.M. Juran, Jurans Quality Control Handbook, McGraw-Hill, 1988.  1  McGraw Gary 2004, Software security, 11-17  McConnell, Steve 1993, Code Complete First ed., Microsoft Press  Crosby, P., Quality is Free , McGraw-Hill, 1979  DeMarco, T., Management Can Make Quality Impossible , Cutter IT Summit, Boston, April 1999  Weinberg, Gerald M. 1992, Quality Software Management Volume 1, Systems Thinking , New York, NY Dorset House Publishing, p.  7  Weinberg, Gerald M. 1993, Quality Software Management Volume 2, First-Order Measurement , New York, NY Dorset House Publishing, p.  108  How to Deliver Resilient, Secure, Efficient and Agile IT Systems in Line with CISQ Recommendations - Whitepaper  Object Management Group PDF . Archived PDF from the original on 2013-12-28 . Retrieved 2013-10-18 . Cite uses deprecated parameter deadurl  help   Park, R.E. 1992. Software Size Measurement A Framework for Counting Source Statements. CMUSEI-92-TR-020. Software Engineering Institute, Carnegie Mellon University  Halstead, M.E. 1977. Elements of Software Science. Elsevier North-Holland.  Chidamber, S.  C. Kemerer. C. 1994. A Metrics Suite for Object Oriented Design. IEEE Transactions on Software Engineering, 20 6, 476-493  Nygard, M.T. 2007. Release It Design and Deploy Production Ready Software. The Pragmatic Programmers.  CWE - Common Weakness Enumeration . cwe.mitre.org . Archived from the original on 2016-05-10 . Retrieved 2016-05-20 . Cite uses deprecated parameter deadurl  help   Boehm, B., Brown, J.R., Kaspar, H., Lipow, M., MacLeod, G.J.,  Merritt, M.J. 1978. Characteristics of Software Quality. North-Holland.  CWE - Common Weakness Enumeration . Cwe.mitre.org. Archived from the original on 2013-10-14 . Retrieved 2013-10-18 . Cite uses deprecated parameter deadurl  help   CWEs Top 25 . Sans.org . Retrieved 2013-10-18 .  IfSQ Level-2 A Foundation-Level Standard for Computer Program Source Code Archived 2011-10-27 at the Wayback Machine , Second Edition August 2008, Graham Bolton, Stuart Johnston, IfSQ, Institute for Software Quality.  Fowler, Martin October 14, 2009. TechnicalDebtQuadrant . Archived from the original on February 2, 2013 . Retrieved February 4, 2013 . Cite uses deprecated parameter deadurl  help   Prause, Christian Durdik, Zoya June 3, 2012. Architectural design and documentation Waste in agile development . 2012 International Conference on Software and System Process ICSSP . IEEE Computer Society. pp.  130134. doi  10.1109ICSSP.2012.6225956 . ISBN   978-1-4673-2352-9 . Retrieved February 4, 2013 .  Wagner, Stefan Goeb, Andreas Heinemann, Lars Kls, Michael Lampasona, Constanza Lochmann, Klaus Mayr, Alois Plsch, Reinhold Seidl, Andreas 2015. Operationalised product quality models and assessment The Quamoco approach PDF . Information and Software Technology . 62  101123. arXiv  1611.09230 . doi  10.1016j.infsof.2015.02.009 .  Suryanarayana, Girish 2015. Software Process versus Design Quality Tug of War. IEEE Software . 32 4 711. doi  10.1109MS.2015.87 . Bibliography .mw-parser-output .refbeginfont-size90margin-bottom0.5em.mw-parser-output .refbegin-hanging-indentsullist-style-typenonemargin-left0.mw-parser-output .refbegin-hanging-indentsulli,.mw-parser-output .refbegin-hanging-indentsdlddmargin-left0padding-left3.2emtext-indent-3.2emlist-stylenone.mw-parser-output .refbegin-100font-size100 Albrecht, A. J. 1979, Measuring application development productivity. In Proceedings of the Joint SHAREGUIDE IBM Applications Development Symposium. , IBM Ben-Menachem, M. Marliss, G. S. 1997, Software Quality, Producing Practical and Consistent Software , Thomson Computer Press Boehm, B. Brown, J.R. Kaspar, H. Lipow, M. MacLeod, G.J. Merritt, M.J. 1978, Characteristics of Software Quality , North-Holland. Chidamber, S. Kemerer, C. 1994, A Metrics Suite for Object Oriented Design. IEEE Transactions on Software Engineering, 20 6 , pp.  476493 Ebert, Christof Dumke, Reiner, Software Measurement Establish - Extract - Evaluate - Execute , Kindle Edition, p.  91 Garmus, D. Herron, D. 2001, Function Point Analysis , Addison Wesley Halstead, M.E. 1977, Elements of Software Science , Elsevier North-Holland Hamill, M. Goseva-Popstojanova, K. 2009, Common faults in software fault and failure data. IEEE Transactions of Software Engineering, 35 4 , pp.  484496 Jackson, D.J. 2009, A direct path to dependable software. Communications of the ACM, 52 4. Martin, R. 2001, Managing vulnerabilities in networked systems , IEEE Computer. McCabe, T. December 1976, A complexity measure. IEEE Transactions on Software Engineering McConnell, Steve 1993, Code Complete First ed., Microsoft Press Nygard, M.T. 2007, Release It Design and Deploy Production Ready Software , The Pragmatic Programmers. Park, R.E. 1992, Software Size Measurement A Framework for Counting Source Statements. CMUSEI-92-TR-020. , Software Engineering Institute, Carnegie Mellon University Pressman, Roger S. 2005. Software Engineering A Practitioners Approach Sixth International ed.. McGraw-Hill Education. ISBN   0071267824 . Spinellis, D. 2006, Code Quality , Addison Wesley External links  edit  Wikimedia Commons has media related to Software quality . Linux Fewer Bugs Than Rivals Wired Magazine, 2004 Automated Function Points  permanent dead link  Beta 1 by OMG v t e Software engineering Fields Computer programming Requirements engineering Software deployment Software design Software maintenance Software testing Systems analysis Formal methods Concepts Data modeling Enterprise architecture Functional specification Modeling language Orthogonality Programming paradigm Software Software archaeology Software architecture Software configuration management Software development methodology Software development process Software quality Software quality assurance Software verification and validation Structured analysis Orientations Agile Aspect-oriented Object orientation Ontology Service orientation SDLC Models Developmental Agile EUP Executable UML Incremental model Iterative model Prototype model RAD UP Scrum Spiral model V-Model Waterfall model XP Other SPICE CMMI Data model ER model Function model Information model Metamodeling Object model Systems model View model Languages IDEF UML USL SysML Software engineers Victor Basili Kent Beck Grady Booch Fred Brooks Barry Boehm Peter Chen Danese Cooper Ward Cunningham Tom DeMarco Edsger W. Dijkstra Delores M. Etter Martin Fowler Adele Goldstine Margaret Hamilton C. A. R. Hoare Lois Haibt Mary Jean Harrold Grace Hopper Watts Humphrey Michael A. Jackson Ivar Jacobson Alan Kay Nancy Leveson Stephen J. Mellor Bertrand Meyer David Parnas Trygve Reenskaug Winston W. Royce James Rumbaugh Mary Shaw Peri Tarr Elaine Weyuker Niklaus Wirth Edward Yourdon Related fields Computer science Computer engineering Project management Risk management Systems engineering Category Commons v t e Computer science Note This template roughly follows the 2012 ACM Computing Classification System . Hardware Printed circuit board Peripheral Integrated circuit Very Large Scale Integration Systems on Chip SoCs Energy consumption Green computing Electronic design automation Hardware acceleration Computer systems organization Computer architecture Embedded system Real-time computing Dependability Networks Network architecture Network protocol Network components Network scheduler Network performance evaluation Network service Software organization Interpreter Middleware Virtual machine Operating system Software quality Software notations and tools Programming paradigm Programming language Compiler Domain-specific language Modeling language Software framework Integrated development environment Software configuration management Software library Software repository Software development Software development process Requirements analysis Software design Software construction Software deployment Software maintenance Programming team Open-source model Theory of computation Model of computation Formal language Automata theory Computational complexity theory Logic Semantics Algorithms Algorithm design Analysis of algorithms Algorithmic efficiency Randomized algorithm Computational geometry Mathematics of computing Discrete mathematics Probability Statistics Mathematical software Information theory Mathematical analysis Numerical analysis Information systems Database management system Information storage systems Enterprise information system Social information systems Geographic information system Decision support system Process control system Multimedia information system Data mining Digital library Computing platform Digital marketing World Wide Web Information retrieval Security Cryptography Formal methods Security services Intrusion detection system Hardware security Network security Information security Application security Humancomputer interaction Interaction design Social computing Ubiquitous computing Visualization Accessibility Concurrency Concurrent computing Parallel computing Distributed computing Multithreading Multiprocessing Artificial intelligence Natural language processing Knowledge representation and reasoning Computer vision Automated planning and scheduling Search methodology Control method Philosophy of artificial intelligence Distributed artificial intelligence Machine learning Supervised learning Unsupervised learning Reinforcement learning Multi-task learning Cross-validation Graphics Animation Rendering Image manipulation Graphics processing unit Mixed reality Virtual reality Image compression Solid modeling Applied computing E-commerce Enterprise software Computational mathematics Computational physics Computational chemistry Computational biology Computational social science Computational engineering Computational healthcare Digital art Electronic publishing Cyberwarfare Electronic voting Video games Word processing Operations research Educational technology Document management Book Category Portal Outline WikiProject Commons Retrieved from  httpsen.wikipedia.orgwindex.phptitleSoftware_quality oldid912473045  Categories  Software quality Systems thinking Software testing Source code Hidden categories CS1 errors deprecated parameters Webarchive template wayback links All articles with unsourced statements Articles with unsourced statements from December 2013 Commons category link from Wikidata All articles with dead external links Articles with dead external links from January 2018 Articles with permanently dead external links
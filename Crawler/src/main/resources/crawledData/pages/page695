Context-free grammar From Wikipedia, the free encyclopedia Jump to navigation Jump to search Type of formal grammar This article needs additional citations for verification . Please help improve this article by adding citations to reliable sources . Unsourced material may be challenged and removed. Find sources   Context-free grammar     news    newspapers    books    scholar    JSTOR  February 2012   Learn how and when to remove this template message  In formal language theory, a context-free grammar  CFG  is a certain type of formal grammar  a set of production rules that describe all possible strings in a given formal language. Production rules are simple replacements. For example, the rule A       displaystyle A to  alpha  replaces A displaystyle A with  displaystyle alpha  . There can be multiple replacement rules for any given value. For example, A       displaystyle A to  alpha  A       displaystyle A to  beta  means that A displaystyle A can be replaced with either  displaystyle alpha  or  displaystyle beta  . In context-free grammars, all rules are one-to-one, one-to-many, or one-to-none. These rules can be applied regardless of context. The left-hand side of the production rule is always a nonterminal symbol. This means that the symbol does not appear in the resulting formal language. So in our case, our language contains the letters  displaystyle alpha  and  displaystyle beta  but not A . displaystyle A. 1  Rules can also be applied in reverse to check whether a string is grammatically correct according to the grammar. Here is an example context-free grammar that describes all two-letter strings containing the letters  displaystyle alpha  or  displaystyle beta  . S      A A displaystyle S to  AA A       displaystyle A to  alpha  A       displaystyle A to  beta  If we start with the nonterminal symbol S displaystyle S then we can use the rule S      A A displaystyle S to  AA to turn S displaystyle S into A A displaystyle AA . We can then apply one of the two later rules. For example, if we apply A       displaystyle A to  beta  to the first A displaystyle A we get  A displaystyle beta A . If we then apply A       displaystyle A to  alpha  to the second A displaystyle A we get   displaystyle beta alpha  . Since both  displaystyle alpha  and  displaystyle beta  are terminal symbols, and in context-free grammars terminal symbols never appear on the left hand side of a production rule, there are no more rules that can be applied. This same process can be used, applying the last two rules in different orders in order to get all possible strings within our simple context-free grammar. Languages generated by context-free grammars are known as context-free languages CFL. Different context-free grammars can generate the same context-free language. It is important to distinguish the properties of the language intrinsic properties from the properties of a particular grammar extrinsic properties. The language equality question do two given context-free grammars generate the same language is undecidable . Context-free grammars arise in linguistics where they are used to describe the structure of sentences and words in a natural language , and they were in fact invented by the linguist Noam Chomsky for this purpose. By contrast, in computer science , as the use of recursively-defined concepts increased, they were used more and more. In an early application, grammars are used to describe the structure of programming languages . In a newer application, they are used in an essential part of the Extensible Markup Language XML called the Document Type Definition . 2  In linguistics , some authors use the term phrase structure grammar to refer to context-free grammars, whereby phrase-structure grammars are distinct from dependency grammars . In computer science , a popular notation for context-free grammars is BackusNaur form , or BNF . Contents 1 Background 2 Formal definitions 2.1 Production rule notation 2.2 Rule application 2.3 Repetitive rule application 2.4 Context-free language 2.5 Proper CFGs 3 Examples 3.1 Words concatenated with their reverse 3.2 Well-formed parentheses 3.3 Well-formed nested parentheses and square brackets 3.4 Matching pairs 3.5 Distinct number of as and bs 3.6 Second block of bs of double size 3.7 First-order logic formulas 4 Examples of languages that are not context free 5 Regular grammars 6 Derivations and syntax trees 6.1 Example Algebraic expressions 7 Normal forms 8 Closure properties 9 Decidable problems 9.1 Parsing 9.2 Reachability, productiveness, nullability 9.3 Regularity and LL k  checks 9.4 Emptiness and finiteness 10 Undecidable problems 10.1 Universality 10.2 Language equality 10.3 Language inclusion 10.4 Being in a lower or higher level of the Chomsky hierarchy 10.5 Grammar ambiguity 10.6 Language disjointness 11 Extensions 12 Subclasses 13 Linguistic applications 14 See also 15 Notes 16 References 17 External links Background  edit  Since the time of Pini , at least, linguists have described the grammars of languages in terms of their block structure, and described how sentences are recursively built up from smaller phrases, and eventually individual words or word elements. An essential property of these block structures is that logical units never overlap. For example, the sentence John, whose blue car was in the garage, walked to the grocery store. can be logically parenthesized with the logical metasymbols    as follows  John  ,  whose  blue car   was  in  the garage  ,   walked  to  the  grocery store  . A context-free grammar provides a simple and mathematically precise mechanism for describing the methods by which phrases in some natural language are built from smaller blocks, capturing the block structure of sentences in a natural way. Its simplicity makes the formalism amenable to rigorous mathematical study. Important features of natural language syntax such as agreement and reference are not part of the context-free grammar, but the basic recursive structure of sentences, the way in which clauses nest inside other clauses, and the way in which lists of adjectives and adverbs are swallowed by nouns and verbs, is described exactly. Context-free grammars are a special form of Semi-Thue systems that in their general form date back to the work of Axel Thue . The formalism of context-free grammars was developed in the mid-1950s by Noam Chomsky , 3  and also their classification as a special type of formal grammar which he called phrase-structure grammars . 4  What Chomsky called a phrase structure grammar is also known now as a constituency grammar, whereby constituency grammars stand in contrast to dependency grammars . In Chomskys generative grammar framework, the syntax of natural language was described by context-free rules combined with transformation rules. Block structure was introduced into computer programming languages by the Algol project 19571960, which, as a consequence, also featured a context-free grammar to describe the resulting Algol syntax. This became a standard feature of computer languages, and the notation for grammars used in concrete descriptions of computer languages came to be known as BackusNaur form , after two members of the Algol language design committee. 3  The block structure aspect that context-free grammars capture is so fundamental to grammar that the terms syntax and grammar are often identified with context-free grammar rules, especially in computer science. Formal constraints not captured by the grammar are then considered to be part of the semantics of the language. Context-free grammars are simple enough to allow the construction of efficient parsing algorithms that, for a given string, determine whether and how it can be generated from the grammar. An Earley parser is an example of such an algorithm, while the widely used LR and LL parsers are simpler algorithms that deal only with more restrictive subsets of context-free grammars. Formal definitions  edit  A context-free grammar G is defined by the 4- tuple  5  G   V ,  , R , S  displaystyle GV,Sigma ,R,S where V is a finite set each element v  V displaystyle vin V is called a nonterminal character or a variable . Each variable represents a different type of phrase or clause in the sentence. Variables are also sometimes called syntactic categories. Each variable defines a sub-language of the language defined by G .  is a finite set of terminal s, disjoint from V , which make up the actual content of the sentence. The set of terminals is the alphabet of the language defined by the grammar G . R is a finite relation from V to  V     displaystyle Vcup Sigma  , where the asterisk represents the Kleene star operation. The members of R are called the rewrite rule s or production s of the grammar. also commonly symbolized by a P  S is the start variable or start symbol, used to represent the whole sentence or program. It must be an element of V . Production rule notation  edit  A production rule in R is formalized mathematically as a pair   ,    R displaystyle alpha ,beta in R , where   V displaystyle alpha in V is a nonterminal and    V     displaystyle beta in Vcup Sigma  is a string of variables andor terminals rather than using ordered pair notation, production rules are usually written using an arrow operator with  as its left hand side and  as its right hand side    displaystyle alpha rightarrow beta  . It is allowed for  to be the empty string , and in this case it is customary to denote it by . The form    displaystyle alpha rightarrow varepsilon  is called an  -production. 6  It is common to list all right-hand sides for the same left-hand side on the same line, using  the pipe symbol  to separate them. Rules    1 displaystyle alpha rightarrow beta _1 and    2 displaystyle alpha rightarrow beta _2 can hence be written as    1   2 displaystyle alpha rightarrow beta _1mid beta _2 . In this case,  1 displaystyle beta _1 and  2 displaystyle beta _2 is called the first and second alternative, respectively. Rule application  edit  For any strings u , v   V     displaystyle u,vin Vcup Sigma  , we say u directly yields v , written as u  v displaystyle uRightarrow v, , if    ,    R displaystyle exists alpha ,beta in R with   V displaystyle alpha in V and u 1 , u 2   V     displaystyle u_1,u_2in Vcup Sigma  such that u  u 1  u 2 displaystyle u,u_1alpha u_2 and v  u 1  u 2 displaystyle v,u_1beta u_2 . Thus, v is a result of applying the rule   ,   displaystyle alpha ,beta  to u . Repetitive rule application  edit  For any strings u , v   V     , displaystyle u,vin Vcup Sigma , we say u yields v , written as u   v displaystyle ustackrel Rightarrow v or u   v displaystyle uRightarrow Rightarrow v, in some textbooks, if  k  1  u 1 ,  , u k   V     displaystyle exists kgeq 1,exists ,u_1,cdots ,u_kin Vcup Sigma  such that u  u 1  u 2    u k  v displaystyle u,u_1Rightarrow u_2Rightarrow cdots Rightarrow u_k,v . In this case, if k  2 displaystyle kgeq 2 i.e., u  v displaystyle uneq v , the relation u   v displaystyle ustackrel Rightarrow v holds. In other words,     displaystyle stackrel Rightarrow  and     displaystyle stackrel Rightarrow  are the reflexive transitive closure allowing a word to yield itself and the transitive closure requiring at least one step of    displaystyle Rightarrow  , respectively. Context-free language  edit  The language of a grammar G   V ,  , R , S  displaystyle GV,Sigma ,R,S is the set L  G    w     S   w  displaystyle LGwin Sigma Sstackrel Rightarrow w A language L is said to be a context-free language CFL, if there exists a CFG G , such that L  L  G  displaystyle L,,LG . Non-deterministic pushdown automata recognize exactly the context-free languages. Proper CFGs  edit  A context-free grammar is said to be proper , 7  if it has no unreachable symbols   N  V    ,    V      S    N  displaystyle forall Nin Vexists alpha ,beta in Vcup Sigma Sstackrel Rightarrow alpha Nbeta  no unproductive symbols   N  V   w     N   w displaystyle forall Nin Vexists win Sigma Nstackrel Rightarrow w no -productions   N  V   N ,    R displaystyle neg exists Nin VN,varepsilon in R no cycles   N  V  N   N displaystyle neg exists Nin VNstackrel Rightarrow N Every context-free grammar can be effectively transformed into a weakly equivalent one without unreachable symbols, 8  a weakly equivalent one without unproductive symbols, 9  and a weakly equivalent one without cycles. 10  Every context-free grammar not producing  can be effectively transformed into a weakly equivalent one without -productions 11  altogether, every such grammar can be effectively transformed into a weakly equivalent proper CFG. Examples  edit  This section needs additional citations for verification . Please help improve this article by adding citations to reliable sources . Unsourced material may be challenged and removed. Find sources   Context-free grammar     news    newspapers    books    scholar    JSTOR  July 2018   Learn how and when to remove this template message  Words concatenated with their reverse  edit  The grammar G    S  ,  a , b  , P , S  displaystyle GS,a,b,P,S , with productions S  aSa , S  bSb , S   , is context-free. It is not proper since it includes an -production. A typical derivation in this grammar is S  aSa  aaSaa  aabSbaa  aabbaa . This makes it clear that L  G    w w R  w   a , b    displaystyle LGwwRwin a,b . The language is context-free, however, it can be proved that it is not regular . If the productions S  a , S  b , are added, a context-free grammar for the set of all palindromes over the alphabet  a , b  is obtained. 12  Well-formed parentheses  edit  The canonical example of a context-free grammar is parenthesis matching, which is representative of the general case. There are two terminal symbols  and  and one nonterminal symbol S. The production rules are S  SS S  S S   The first rule allows the S symbol to multiply the second rule allows the S symbol to become enclosed by matching parentheses and the third rule terminates the recursion. 13  Well-formed nested parentheses and square brackets  edit  A second canonical example is two different kinds of matching nested parentheses, described by the productions S  SS S   S  S S   S  S with terminal symbols     and nonterminal S. The following sequence can be derived in that grammar            Matching pairs  edit  In a context-free grammar, we can pair up characters the way we do with brackets . The simplest example S  aSb S  ab This grammar generates the language  a n b n  n  1  displaystyle anbnngeq 1 , which is not regular according to the pumping lemma for regular languages . The special character  stands for the empty string. By changing the above grammar to S  aSb   we obtain a grammar generating the language  a n b n  n  0  displaystyle anbnngeq 0 instead. This differs only in that it contains the empty string while the original grammar did not. Distinct number of as and bs  edit  A context-free grammar for the language consisting of all strings over a,b containing an unequal number of as and bs S  U  V U  TaU  TaT  UaT V  TbV  TbT  VbT T  aTbT  bTaT   Here, the nonterminal T can generate all strings with the same number of as as bs, the nonterminal U generates all strings with more as than bs and the nonterminal V generates all strings with fewer as than bs. Omitting the third alternative in the rule for U and V doesnt restrict the grammars language. Second block of bs of double size  edit  Another example of a non-regular language is  b n a m b 2 n  n  0 , m  0  displaystyle bnamb2nngeq 0,mgeq 0 . It is context-free as it can be generated by the following context-free grammar S  bSbb  A A  aA   First-order logic formulas  edit  The formation rules for the terms and formulas of formal logic fit the definition of context-free grammar, except that the set of symbols may be infinite and there may be more than one start symbol. Examples of languages that are not context free  edit  In contrast to well-formed nested parentheses and square brackets in the previous section, there is no context-free grammar for generating all sequences of two different types of parentheses, each separately balanced disregarding the other , where the two types need not nest inside one another, for example     or               The fact that this language is not context free can be proven using Pumping lemma for context-free languages and a proof by contradiction, observing that all words of the form  n  n  n  n displaystyle nnnn should belong to the language. This language belongs instead to a more general class and can be described by a conjunctive grammar , which in turn also includes other non-context-free languages, such as the language of all words of the form a n b n c n displaystyle anbncn . Regular grammars  edit  Main article Regular grammar Every regular grammar is context-free, but not all context-free grammars are regular. 14  The following context-free grammar, however, is also regular. S  a S  aS S  bS The terminals here are a and b , while the only nonterminal is S. The language described is all nonempty strings of a displaystyle a s and b displaystyle b s that end in a displaystyle a . This grammar is regular  no rule has more than one nonterminal in its right-hand side, and each of these nonterminals is at the same end of the right-hand side. Every regular grammar corresponds directly to a nondeterministic finite automaton , so we know that this is a regular language . Using pipe symbols, the grammar above can be described more tersely as follows S  a  aS  bS Derivations and syntax trees  edit  A derivation of a string for a grammar is a sequence of grammar rule applications that transform the start symbol into the string. A derivation proves that the string belongs to the grammars language. A derivation is fully determined by giving, for each step the rule applied in that step the occurrence of its left-hand side to which it is applied For clarity, the intermediate string is usually given as well. For instance, with the grammar 1 S  S  S 2 S  1 3 S  a the string 1  1  a can be derived with the derivation S  rule 1 on the first S SS  rule 1 on the second S SSS  rule 2 on the second S S1S  rule 3 on the third S S1a  rule 2 on the first S 11a Often, a strategy is followed that deterministically determines the next nonterminal to rewrite in a leftmost derivation , it is always the leftmost nonterminal in a rightmost derivation , it is always the rightmost nonterminal. Given such a strategy, a derivation is completely determined by the sequence of rules applied. For instance, the leftmost derivation S  rule 1 on the first S SS  rule 2 on the first S 1S  rule 1 on the first S 1SS  rule 2 on the first S 11S  rule 3 on the first S 11a can be summarized as rule 1, rule 2, rule 1, rule 2, rule 3 The distinction between leftmost derivation and rightmost derivation is important because in most parsers the transformation of the input is defined by giving a piece of code for every grammar rule that is executed whenever the rule is applied. Therefore, it is important to know whether the parser determines a leftmost or a rightmost derivation because this determines the order in which the pieces of code will be executed. See for an example LL parsers and LR parsers . A derivation also imposes in some sense a hierarchical structure on the string that is derived. For example, if the string 1  1  a is derived according to the leftmost derivation S  S  S 1      1  S 2      1  S  S 1      1  1  S 2      1  1  a 3 the structure of the string would be   1  S    1  S   a  S  S  S where  ...  S indicates a substring recognized as belonging to S. This hierarchy can also be seen as a tree This tree is called a parse tree or concrete syntax tree of the string, by contrast with the abstract syntax tree . In this case the presented leftmost and the rightmost derivations define the same parse tree however, there is another rightmost derivation of the same string S  S  S 1      S  a 3      S  S  a 1      S  1  a 2      1  1  a 2 and this defines the following parse tree Note however that both parse trees can be obtained by both leftmost and rightmost derivations. For example, the last tree can be obtained with the leftmost derivation as follows S  S  S 1      S  S  S 1      1  S  S 2      1  1  S 2      1  1  a 3 If a string in the language of the grammar has more than one parsing tree, then the grammar is said to be an ambiguous grammar . Such grammars are usually hard to parse because the parser cannot always decide which grammar rule it has to apply. Usually, ambiguity is a feature of the grammar, not the language, and an unambiguous grammar can be found that generates the same context-free language. However, there are certain languages that can only be generated by ambiguous grammars such languages are cal led inherently ambiguous languages . Example Algebraic expressions  edit  Here is a context-free grammar for syntactically correct infix algebraic expressions in the variables x, y and z S  x S  y S  z S  S  S S  S - S S  S  S S  S  S S   S  This grammar can, for example, generate the string  x  y   x - z  y   x  x  as follows S the start symbol  S - S by rule 5  S  S - S by rule 6, applied to the leftmost S  S  S - S  S by rule 7, applied to the rightmost S   S   S - S  S by rule 8, applied to the leftmost S   S   S - S   S  by rule 8, applied to the rightmost S   S  S   S - S   S  etc.   S  S   S - S  S   S    S  S   S - S  S   S  S    x  S   S - S  S   S  S    x  y   S - S  S   S  S    x  y   x - S  y   S  S    x  y   x - S  y   x  S    x  y   x - z  y   x  S    x  y   x - z  y   x  x  Note that many choices were made underway as to which rewrite was going to be performed next. These choices look quite arbitrary. As a matter of fact, they are, in the sense that the string finally generated is always the same. For example, the second and third rewrites  S  S - S by rule 6, applied to the leftmost S  S  S - S  S by rule 7, applied to the rightmost S could be done in the opposite order  S - S  S by rule 7, applied to the rightmost S  S  S - S  S by rule 6, applied to the leftmost S Also, many choices were made on which rule to apply to each selected S . Changing the choices made and not only the order they were made in usually affects which terminal string comes out at the end. Lets look at this in more detail. Consider the parse tree of this derivation Starting at the top, step by step, an S in the tree is expanded, until no more unexpanded S es nonterminals remain. Picking a different order of expansion will produce a different derivation, but the same parse tree. The parse tree will only change if we pick a different rule to apply at some position in the tree. But can a different parse tree still produce the same terminal string, which is  x  y   x - z  y   x  x  in this case Yes, for this particular grammar, this is possible. Grammars with this property are called ambiguous . For example, x  y  z can be produced with these two different parse trees However, the language described by this grammar is not inherently ambiguous an alternative, unambiguous grammar can be given for the language, for example T  x T  y T  z S  S  T S  S - T S  S  T S  S  T T   S  S  T once again picking S as the start symbol. This alternative grammar will produce x  y  z with a parse tree similar to the left one above, i.e. implicitly assuming the association x  y  z , which is not according to standard operator precedence. More elaborate, unambiguous and context-free grammars can be constructed that produce parse trees that obey all desired operator precedence and associativity rules. Normal forms  edit  Every context-free grammar that does not generate the empty string can be transformed into one in which there is no -production that is, a rule that has the empty string as a product. If a grammar does generate the empty string, it will be necessary to include the rule S   displaystyle Srightarrow epsilon  , but there need be no other -rule. Every context-free grammar with no -production has an equivalent grammar in Chomsky normal form , and a grammar in Greibach normal form . Equivalent here means that the two grammars generate the same language. The especially simple form of production rules in Chomsky normal form grammars has both theoretical and practical implications. For instance, given a context-free grammar, one can use the Chomsky normal form to construct a polynomial-time algorithm that decides whether a given string is in the language represented by that grammar or not the CYK algorithm . Closure properties  edit  Context-free languages are closed under the various operations, that is, if the languages K and L are context-free, so is the result of the following operations union K  L  concatenation K  L  Kleene star L  15  substitution in particular homomorphism  16  inverse homomorphism 17  intersection with a regular language 18  They are not closed under general intersection hence neither under complementation  and set difference. 19  Decidable problems  edit  The following are some decidable problems about context-free grammars. Parsing  edit  The parsing problem, checking whether a given word belongs to the language given by a context-free grammar, is decidable, using one of the general-purpose parsing algorithms CYK algorithm for grammars in Chomsky normal form  Earley parser GLR parser LL parser only for the proper subclass of for LL k  grammars Context-free parsing for Chomsky normal form grammars was shown by Leslie G. Valiant to be reducible to boolean matrix multiplication , thus inheriting its complexity upper bound of O  n 2.3728639 . 20  21  note 1  Conversely, Lillian Lee has shown O  n 3  boolean matrix multiplication to be reducible to O  n 33  CFG parsing, thus establishing some kind of lower bound for the latter. 22  Reachability, productiveness, nullability  edit  It is decidable whether a given non-terminal of a context-free grammar is reachable, 23  whether it is productive, 24  and whether it is nullable that is, it can derive the empty string. 25  Regularity and LL k  checks  edit  It is decidable whether a given grammar is a regular grammar , 26  as well as whether it is an LL k  grammar for a given k 0. 27   233 If k is not given, the latter problem is undecidable. 27   252 Given a context-free language , it is neither decidable whether it is regular, 28  nor whether it is an LL k  language for a given k . 27   254 Emptiness and finiteness  edit  There are algorithms to decide whether a language of a given context-free language is empty, as well as whether it is finite. 29  Undecidable problems  edit  Some questions that are undecidable for wider classes of grammars become decidable for context-free grammars e.g. the emptiness problem whether the grammar generates any terminal strings at all, is undecidable for context-sensitive grammars , but decidable for context-free grammars. However, many problems are undecidable even for context-free grammars. Examples are Universality  edit  Given a CFG, does it generate the language of all strings over the alphabet of terminal symbols used in its rules 30  31  A reduction can be demonstrated to this problem from the well-known undecidable problem of determining whether a Turing machine accepts a particular input the halting problem . The reduction uses the concept of a computation history , a string describing an entire computation of a Turing machine . A CFG can be constructed that generates all strings that are not accepting computation histories for a particular Turing machine on a particular input, and thus it will accept all strings only if the machine doesnt accept that input. Language equality  edit  Given two CFGs, do they generate the same language 31  32  The undecidability of this problem is a direct consequence of the previous it is impossible to even decide whether a CFG is equivalent to the trivial CFG defining the language of all strings. Language inclusion  edit  Given two CFGs, can the first one generate all strings that the second one can generate 31  32  If this problem was decidable, then language equality could be decided too two CFGs G1 and G2 generate the same language if LG1 is a subset of LG2 and LG2 is a subset of LG1. Being in a lower or higher level of the Chomsky hierarchy  edit  Using Greibachs theorem , it can be shown that the two following problems are undecidable Given a context-sensitive grammar , does it describe a context-free language Given a context-free grammar, does it describe a regular language  31  32  Grammar ambiguity  edit  Given a CFG, is it ambiguous  The undecidability of this problem follows from the fact that if an algorithm to determine ambiguity existed, the Post correspondence problem could be decided, which is known to be undecidable. Language disjointness  edit  Given two CFGs, is there any string derivable from both grammars If this problem was decidable, the undecidable Post correspondence problem could be decided, too given strings  1 ,  ,  N ,  1 ,  ,  N displaystyle alpha _1,ldots ,alpha _N,beta _1,ldots ,beta _N over some alphabet  a 1 ,  , a k  displaystyle a_1,ldots ,a_k , let the grammar G 1 displaystyle G_1 consist of the rule S   1 S  1 r e v     N S  N r e v  b displaystyle Sto alpha _1Sbeta _1revcdots alpha _NSbeta _Nrevb  where  i r e v displaystyle beta _irev denotes the reversed string  i displaystyle beta _i and b displaystyle b doesnt occur among the a i displaystyle a_i  and let grammar G 2 displaystyle G_2 consist of the rule T  a 1 T a 1    a k T a k  b displaystyle Tto a_1Ta_1cdots a_kTa_kb  Then the Post problem given by  1 ,  ,  N ,  1 ,  ,  N displaystyle alpha _1,ldots ,alpha _N,beta _1,ldots ,beta _N has a solution if and only if L  G 1  displaystyle LG_1 and L  G 2  displaystyle LG_2 share a derivable string. Extensions  edit  An obvious way to extend the context-free grammar formalism is to allow nonterminals to have arguments, the values of which are passed along within the rules. This allows natural language features such as agreement and reference , and programming language analogs such as the correct use and definition of identifiers, to be expressed in a natural way. E.g. we can now easily express that in English sentences, the subject and verb must agree in number. In computer science, examples of this approach include affix grammars , attribute grammars , indexed grammars , and Van Wijngaarden two-level grammars . Similar extensions exist in linguistics. An extended context-free grammar or regular right part grammar  is one in which the right-hand side of the production rules is allowed to be a regular expression over the grammars terminals and nonterminals. Extended context-free grammars describe exactly the context-free languages. 33  Another extension is to allow additional terminal symbols to appear at the left-hand side of rules, constraining their application. This produces the formalism of context-sensitive grammars . Subclasses  edit  There are a number of important subclasses of the context-free grammars LR k  grammars also known as deterministic context-free grammars  allow parsing string recognition with deterministic pushdown automata PDA, but they can only describe deterministic context-free languages . Simple LR , Look-Ahead LR grammars are subclasses that allow further simplification of parsing. SLR and LALR are recognized using the same PDA as LR, but with simpler tables, in most cases. LL k  and LL   grammars allow parsing by direct construction of a leftmost derivation as described above, and describe even fewer languages. Simple grammars are a subclass of the LL1 grammars mostly interesting for its theoretical property that language equality of simple grammars is decidable, while language inclusion is not. Bracketed grammars have the property that the terminal symbols are divided into left and right bracket pairs that always match up in rules. Linear grammars have no rules with more than one nonterminal on the right-hand side. Regular grammars are a subclass of the linear grammars and describe the regular languages, i.e. they correspond to finite automata and regular expressions . LR parsing extends LL parsing to support a larger range of grammars in turn, generalized LR parsing extends LR parsing to support arbitrary context-free grammars. On LL grammars and LR grammars, it essentially performs LL parsing and LR parsing, respectively, while on nondeterministic grammars , it is as efficient as can be expected. Although GLR parsing was developed in the 1980s, many new language definitions and parser generators continue to be based on LL, LALR or LR parsing up to the present day. Linguistic applications  edit  Chomsky initially hoped to overcome the limitations of context-free grammars by adding transformation rules . 4  Such rules are another standard device in traditional linguistics e.g. passivization in English. Much of generative grammar has been devoted to finding ways of refining the descriptive mechanisms of phrase-structure grammar and transformation rules such that exactly the kinds of things can be expressed that natural language actually allows. Allowing arbitrary transformations does not meet that goal they are much too powerful, being Turing complete unless significant restrictions are added e.g. no transformations that introduce and then rewrite symbols in a context-free fashion. Chomskys general position regarding the non-context-freeness of natural language has held up since then, 34  although his specific examples regarding the inadequacy of context-free grammars in terms of their weak generative capacity were later disproved. 35  Gerald Gazdar and Geoffrey Pullum have argued that despite a few non-context-free constructions in natural language such as cross-serial dependencies in Swiss German 34  and reduplication in Bambara 36  , the vast majority of forms in natural language are indeed context-free. 35  See also  edit  Parsing expression grammar Stochastic context-free grammar Algorithms for context-free grammar generation Pumping lemma for context-free languages Notes  edit   Stephen Scheinberg, Note on the Boolean Properties of Context-Free Languages , Information and Control, 3 , 372375 1960.  Introduction to Automata Theory, Languages, and Computation , John E. Hopcroft, Rajeev Motwani, Jeffrey D. Ullman, Addison Wesley, 2001, p.191  a b Hopcroft  Ullman 1979 , p.  106.  a b Chomsky, Noam Sep 1956, Three models for the description of language PDF , IEEE Transactions on Information Theory , 2 3 113124, doi  10.1109TIT.1956.1056813 , archived from the original PDF on 2013-10-18 , retrieved 2007-06-18 .mw-parser-output cite.citationfont-styleinherit.mw-parser-output .citation qquotes.mw-parser-output .citation .cs1-lock-free abackgroundurlupload.wikimedia.orgwikipediacommonsthumb665Lock-green.svg9px-Lock-green.svg.pngno-repeatbackground-positionright .1em center.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration abackgroundurlupload.wikimedia.orgwikipediacommonsthumbdd6Lock-gray-alt-2.svg9px-Lock-gray-alt-2.svg.pngno-repeatbackground-positionright .1em center.mw-parser-output .citation .cs1-lock-subscription abackgroundurlupload.wikimedia.orgwikipediacommonsthumbaaaLock-red-alt-2.svg9px-Lock-red-alt-2.svg.pngno-repeatbackground-positionright .1em ce nter.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registrationcolor555.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration spanborder-bottom1px dottedcursorhelp.mw-parser-output .cs1-ws-icon abackgroundurlupload.wikimedia.orgwikipediacommonsthumb44cWikisource-logo.svg12px-Wikisource-logo.svg.pngno-repeatbackground-positionright .1em center.mw-parser-output code.cs1-codecolorinheritbackgroundinheritborderinheritpaddinginherit.mw-parser-output .cs1-hidden-errordisplaynonefont-size100.mw-parser-output .cs1-visible-errorfont-size100.mw-parser-output .cs1-maintdisplaynonecolor33aa33margin-left0.3em.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-outpu t .cs1-formatfont-size95.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-leftpadding-left0.2em.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-rightpadding-right0.2em  The notation here is that of Sipser 1997 , p.  94. Hopcroft  Ullman 1979 p.  79 define context-free grammars as 4-tuples in the same way, but with different variable names.  Hopcroft  Ullman 1979 , pp. 9092.  Nijholt, Anton 1980, Context-free grammars covers, normal forms, and parsing , Lecture Notes in Computer Science, 93 , Springer, p.  8, ISBN   978-3-540-10245-8 , MR   0590047 .  Hopcroft  Ullman 1979, p.88, Lemma 4.1  Hopcroft  Ullman 1979, p.89, Lemma 4.2  This is a consequence of the unit-production elimination theorem in Hopcroft  Ullman 1979, p.91, Theorem 4.4  Hopcroft  Ullman 1979, p.91, Theorem 4.4  Hopcroft  Ullman 1979 , Exercise 4.1a, p.  103.  Hopcroft  Ullman 1979 , Exercise 4.1b, p.  103.  Aho, Alfred Vaino  Lam, Monica S.  Sethi, Ravi  Ullman, Jeffrey David 2007. 4.2.7 Context-Free Grammars Versus Regular Expressions print . Compilers Principles, Techniques,  Tools 2nd ed.. Boston, MA USA Pearson Addison-Wesley. pp.  205206. ISBN   9780321486813 . Every construct that can be described by a regular expression can be described by a context-free grammar, but not vice-versa.  Hopcroft  Ullman 1979, p.131, Theorem 6.1  Hopcroft  Ullman 1979, pp.131132, Theorem 6.2  Hopcroft  Ullman 1979, pp.132134, Theorem 6.3  Hopcroft  Ullman 1979, pp.135136, Theorem 6.5  Hopcroft  Ullman 1979, pp.134135, Theorem 6.4  Leslie Valiant Jan 1974. General context-free recognition in less than cubic time Technical report. Carnegie Mellon University. p.  11.  Leslie G. Valiant 1975. General context-free recognition in less than cubic time. Journal of Computer and System Sciences . 10 2 308315. doi  10.1016s0022-00007580046-8 .  Lillian Lee 2002. Fast Context-Free Grammar Parsing Requires Fast Boolean Matrix Multiplication PDF . J ACM . 49 1 115. arXiv  cs0112018 . doi  10.1145505241.505242 .  Hopcroft  Ullman 1979 , Lemma 4.2, p.  89.  Hopcroft  Ullman 1979 , Lemma 4.1, p.  88.  Hopcroft  Ullman 1979 , Theorem 4.3, p.  90.  This is easy to see from the grammar definitions.  a b c D.J. Rosenkrantz and R.E. Stearns 1970. Properties of Deterministic Top Down Grammars. Information and Control . 17 3 226256. doi  10.1016S0019-99587090446-8 .  Hopcroft  Ullman 1979 , Exercise 8.10a, p.  214. The problem remains undecidable even if the language is produced by a linear context-free grammar i.e., with at most one nonterminal in each rules right-hand side, cf. Exercise 4.20, p.  105.  Hopcroft  Ullman 1979, pp.137138, Theorem 6.6  Sipser 1997 , Theorem 5.10, p. 181.  a b c d Hopcroft  Ullman 1979 , p. 281.  a b c Hazewinkel, Michiel 1994, Encyclopaedia of mathematics an updated and annotated translation of the Soviet Mathematical Encyclopaedia , Springer, Vol. IV, p. 56, ISBN   978-1-55608-003-6 .  Norvell, Theodore. A Short Introduction to Regular Expressions and Context-Free Grammars PDF . p.  4 . Retrieved August 24, 2012 .  a b Shieber, Stuart 1985, Evidence against the context-freeness of natural language PDF , Linguistics and Philosophy , 8 3 333343, doi  10.1007BF00630917 .  a b Pullum, Geoffrey K. Gerald Gazdar 1982, Natural languages and context-free languages, Linguistics and Philosophy , 4 4 471504, doi  10.1007BF00360802 .  Culy, Christopher 1985, The Complexity of the Vocabulary of Bambara, Linguistics and Philosophy , 8 3 345351, doi  10.1007BF00630918 .  In Valiants papers, O  n 2.81  given, the then best known upper bound. See Matrix multiplicationAlgorithms for efficient matrix multiplication and CoppersmithWinograd algorithm for bound improvements since then. References  edit  Hopcroft, John E.  Ullman, Jeffrey D. 1979, Introduction to Automata Theory, Languages, and Computation , Addison-Wesley . Chapter 4 Context-Free Grammars, pp.  77106 Chapter 6 Properties of Context-Free Languages, pp.  125137. Sipser, Michael 1997, Introduction to the Theory of Computation , PWS Publishing, ISBN   978-0-534-94728-6 . Chapter 2 Context-Free Grammars, pp.  91122 Section 4.1.2 Decidable problems concerning context-free languages, pp.  156159 Section 5.1.1 Reductions via computation histories pp.  176183. J. Berstel, L. Boasson 1990. Jan van Leeuwen ed.. Context-Free Languages . Handbook of Theoretical Computer Science. B . Elsevier. pp.  59102. External links  edit  Computer programmers may find the stack exchange answer to be useful. Non-computer programmers will find more academic introductory materials to be enlightening. v t e Automata theory  formal languages and formal grammars Chomsky hierarchy Grammars Languages Abstract machines Type-0  Type-1      Type-2   Type-3   Unrestricted no common name Context-sensitive Positive range concatenation Indexed  Linear context-free rewriting systems Tree-adjoining Context-free Deterministic context-free Visibly pushdown Regular  Non-recursive Recursively enumerable Decidable Context-sensitive Positive range concatenation  Indexed   Linear context-free rewriting language Tree-adjoining Context-free Deterministic context-free Visibly pushdown Regular Star-free Finite Turing machine Decider Linear-bounded PTIME Turing Machine Nested stack Thread automaton restricted Tree stack automaton Embedded pushdown Nondeterministic pushdown Deterministic pushdown Visibly pushdown Finite Counter-free with aperiodic finite monoid Acyclic finite Each category of languages, except those marked by a  , is a proper subset of the category directly above it. Any language in each category is generated by a grammar and by an automaton in the category in the same line. Retrieved from  httpsen.wikipedia.orgwindex.phptitleContext-free_grammar oldid914181322  Categories  1956 in computer science Compiler construction Formal languages Programming language topics Hidden categories Articles with short description Use American English from January 2019 All Wikipedia articles written in American English Articles needing additional references from February 2012 All articles needing additional references Articles needing additional references from July 2018 Wikipedia articles with ASCII art